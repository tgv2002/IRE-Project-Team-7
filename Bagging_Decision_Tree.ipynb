{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f9151f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-25T15:19:38.758712Z",
     "iopub.status.busy": "2021-10-25T15:19:38.758235Z",
     "iopub.status.idle": "2021-10-25T15:19:51.031618Z",
     "shell.execute_reply": "2021-10-25T15:19:51.032096Z"
    },
    "id": "Z1N9bc-Cf_m7",
    "papermill": {
     "duration": 12.292372,
     "end_time": "2021-10-25T15:19:51.032383",
     "exception": false,
     "start_time": "2021-10-25T15:19:38.740011",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "import nltk\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from nltk.corpus import stopwords\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models.keyedvectors import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "851ffb21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-25T15:19:51.049376Z",
     "iopub.status.busy": "2021-10-25T15:19:51.048883Z",
     "iopub.status.idle": "2021-10-25T15:19:51.050453Z",
     "shell.execute_reply": "2021-10-25T15:19:51.050833Z"
    },
    "id": "hTEZ3LAngLCv",
    "papermill": {
     "duration": 0.011429,
     "end_time": "2021-10-25T15:19:51.050943",
     "exception": false,
     "start_time": "2021-10-25T15:19:51.039514",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_metrics(y_true, y_pred):\n",
    "    result1 = classification_report(y_true, y_pred)\n",
    "    print('Classification Report: ', result1)\n",
    "    result2 = accuracy_score(y_true, y_pred)\n",
    "    print('Accuracy: ', result2, \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69e7be3e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-10-25T15:19:51.071510Z",
     "iopub.status.busy": "2021-10-25T15:19:51.071027Z",
     "iopub.status.idle": "2021-10-25T15:19:51.175609Z",
     "shell.execute_reply": "2021-10-25T15:19:51.176021Z"
    },
    "id": "uIvEjix7gQRj",
    "outputId": "1fb37836-6650-4b05-a81c-b40f99a853fe",
    "papermill": {
     "duration": 0.116829,
     "end_time": "2021-10-25T15:19:51.176193",
     "exception": false,
     "start_time": "2021-10-25T15:19:51.059364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home2/tgv2002/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45de0b47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-25T15:19:51.195798Z",
     "iopub.status.busy": "2021-10-25T15:19:51.195299Z",
     "iopub.status.idle": "2021-10-25T15:19:51.199453Z",
     "shell.execute_reply": "2021-10-25T15:19:51.198959Z"
    },
    "id": "CX9H85mEgRn8",
    "papermill": {
     "duration": 0.015123,
     "end_time": "2021-10-25T15:19:51.199556",
     "exception": false,
     "start_time": "2021-10-25T15:19:51.184433",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    " stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12cbd3f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-25T15:19:51.219901Z",
     "iopub.status.busy": "2021-10-25T15:19:51.219432Z",
     "iopub.status.idle": "2021-10-25T15:19:51.221572Z",
     "shell.execute_reply": "2021-10-25T15:19:51.221175Z"
    },
    "id": "LA6HfIqfgTNQ",
    "papermill": {
     "duration": 0.014123,
     "end_time": "2021-10-25T15:19:51.221672",
     "exception": false,
     "start_time": "2021-10-25T15:19:51.207549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_post(post):\n",
    "    post = post.lower()\n",
    "    post = re.sub(r\"\\n\", \" \", post)\n",
    "    post = re.sub(\"[\\<\\[].*?[\\>\\]]\", \" \", post)\n",
    "    post = re.sub(r\"[^a-z ]\", \" \", post)\n",
    "    post = re.sub(r\"\\b\\w{1,3}\\b\", \" \", post)\n",
    "    return \" \".join([x for x in post.split() if x not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5715b760",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-25T15:19:51.280478Z",
     "iopub.status.busy": "2021-10-25T15:19:51.279948Z",
     "iopub.status.idle": "2021-10-25T15:19:51.281942Z",
     "shell.execute_reply": "2021-10-25T15:19:51.282431Z"
    },
    "id": "71AR95q8gUqZ",
    "papermill": {
     "duration": 0.053173,
     "end_time": "2021-10-25T15:19:51.282560",
     "exception": false,
     "start_time": "2021-10-25T15:19:51.229387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler, TomekLinks, NearMiss, ClusterCentroids\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "def balance_data(x, y, _type):\n",
    "    if _type == 0:\n",
    "        ros = RandomOverSampler(random_state=42)\n",
    "        return ros.fit_resample(x, y)\n",
    "    elif _type == 1:\n",
    "        rus = RandomUnderSampler(random_state=42, replacement=True)\n",
    "        return rus.fit_resample(x, y)\n",
    "    elif _type == 2:\n",
    "        smote = SMOTE()\n",
    "        return smote.fit_resample(x, y)\n",
    "    elif _type == 3:\n",
    "        nm = NearMiss()\n",
    "        return nm.fit_resample(x, y)\n",
    "    elif _type == 4:\n",
    "        smt = SMOTETomek(ratio='auto')\n",
    "        return smt.fit_resample(x, y)\n",
    "    elif _type == 5:\n",
    "        cc = ClusterCentroids()\n",
    "        return cc.fit_resample(x, y)\n",
    "    elif _type == 6:\n",
    "        tl = TomekLinks()\n",
    "        return tl.fit_resample(x, y)\n",
    "\n",
    "    smote = SMOTE()\n",
    "    return smote.fit_resample(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e094d68",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-10-25T15:19:51.303132Z",
     "iopub.status.busy": "2021-10-25T15:19:51.302625Z",
     "iopub.status.idle": "2021-10-25T15:20:59.060407Z",
     "shell.execute_reply": "2021-10-25T15:20:59.060877Z"
    },
    "id": "jFXVnznpgWKc",
    "outputId": "c18dc80e-3167-4c56-f9b4-185c3a84697e",
    "papermill": {
     "duration": 67.77059,
     "end_time": "2021-10-25T15:20:59.061112",
     "exception": false,
     "start_time": "2021-10-25T15:19:51.290522",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                mental_disorder                              \n",
      "                          count unique            top    freq\n",
      "mental_disorder                                              \n",
      "EDAnonymous               14577      1    EDAnonymous   14577\n",
      "addiction                  7641      1      addiction    7641\n",
      "adhd                      45631      1           adhd   45631\n",
      "alcoholism                 5911      1     alcoholism    5911\n",
      "anxiety                   57671      1        anxiety   57671\n",
      "autism                     8869      1         autism    8869\n",
      "bipolarreddit              5780      1  bipolarreddit    5780\n",
      "bpd                       24294      1            bpd   24294\n",
      "depression               117331      1     depression  117331\n",
      "healthanxiety              8648      1  healthanxiety    8648\n",
      "lonely                    23635      1         lonely   23635\n",
      "ptsd                       8643      1           ptsd    8643\n",
      "schizophrenia              8712      1  schizophrenia    8712\n",
      "socialanxiety             22996      1  socialanxiety   22996\n",
      "suicidewatch              66161      1   suicidewatch   66161\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('/home2/tgv2002/reddit_mental_health_dataset/reddit_dataset.csv')\n",
    "data = shuffle(data)\n",
    "\n",
    "# Class split stats\n",
    "print(data.groupby(['mental_disorder'])[['mental_disorder']].describe())\n",
    "x = data['post'].apply(lambda post: clean_post(post))\n",
    "\n",
    "# Vectorizing text data\n",
    "count_vect = CountVectorizer()\n",
    "X_counts = count_vect.fit_transform(x)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X = tfidf_transformer.fit_transform(X_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffd5310a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-25T15:20:59.156359Z",
     "iopub.status.busy": "2021-10-25T15:20:59.126745Z",
     "iopub.status.idle": "2021-10-25T15:20:59.508105Z",
     "shell.execute_reply": "2021-10-25T15:20:59.507678Z"
    },
    "id": "-223yjJBgXqP",
    "papermill": {
     "duration": 0.438092,
     "end_time": "2021-10-25T15:20:59.508215",
     "exception": false,
     "start_time": "2021-10-25T15:20:59.070123",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(np.array(data['mental_disorder']))\n",
    "# y = to_categorical(y1)\n",
    "\n",
    "# 60-20-20 split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=321)\n",
    "X_test, X_valid, y_test, y_valid = train_test_split(X_test, y_test, test_size=0.5, random_state=321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b225b4c8",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-10-25T15:20:59.530623Z",
     "iopub.status.busy": "2021-10-25T15:20:59.530166Z",
     "iopub.status.idle": "2021-10-26T18:24:41.806874Z",
     "shell.execute_reply": "2021-10-26T18:24:41.809677Z"
    },
    "id": "D2ttwX1wge7y",
    "outputId": "4905873f-8936-459c-89e7-c31ed7b89100",
    "papermill": {
     "duration": 97422.29393,
     "end_time": "2021-10-26T18:24:41.810055",
     "exception": false,
     "start_time": "2021-10-25T15:20:59.516125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################################################################################################\n",
      "\n",
      "With sampling type: 1\n",
      "\n",
      "For training set\n",
      "\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91      3511\n",
      "           1       0.91      0.91      0.91      3511\n",
      "           2       0.89      0.90      0.89      3511\n",
      "           3       0.92      0.94      0.93      3511\n",
      "           4       0.76      0.71      0.73      3511\n",
      "           5       0.94      0.90      0.92      3511\n",
      "           6       0.87      0.77      0.81      3511\n",
      "           7       0.73      0.72      0.73      3511\n",
      "           8       0.68      0.61      0.64      3511\n",
      "           9       0.88      0.92      0.90      3511\n",
      "          10       0.74      0.83      0.78      3511\n",
      "          11       0.91      0.89      0.90      3511\n",
      "          12       0.91      0.88      0.89      3511\n",
      "          13       0.78      0.81      0.79      3511\n",
      "          14       0.70      0.79      0.74      3511\n",
      "\n",
      "    accuracy                           0.83     52665\n",
      "   macro avg       0.83      0.83      0.83     52665\n",
      "weighted avg       0.83      0.83      0.83     52665\n",
      "\n",
      "Accuracy:  0.8335896705591949 \n",
      "\n",
      "\n",
      "\n",
      "For validation set\n",
      "\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.87      0.73      2923\n",
      "           1       0.58      0.81      0.68      1525\n",
      "           2       0.85      0.81      0.83      9280\n",
      "           3       0.62      0.85      0.72      1159\n",
      "           4       0.76      0.57      0.65     11539\n",
      "           5       0.62      0.79      0.70      1762\n",
      "           6       0.34      0.68      0.46      1087\n",
      "           7       0.42      0.54      0.47      4842\n",
      "           8       0.73      0.43      0.54     23492\n",
      "           9       0.46      0.83      0.59      1719\n",
      "          10       0.45      0.72      0.55      4753\n",
      "          11       0.56      0.77      0.65      1694\n",
      "          12       0.57      0.71      0.64      1794\n",
      "          13       0.50      0.67      0.57      4614\n",
      "          14       0.58      0.64      0.61     13117\n",
      "\n",
      "    accuracy                           0.62     85300\n",
      "   macro avg       0.58      0.71      0.63     85300\n",
      "weighted avg       0.65      0.62      0.61     85300\n",
      "\n",
      "Accuracy:  0.6155685814771396 \n",
      "\n",
      "\n",
      "\n",
      "For test set\n",
      "\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.86      0.72      2915\n",
      "           1       0.55      0.80      0.66      1450\n",
      "           2       0.84      0.81      0.83      9083\n",
      "           3       0.62      0.83      0.71      1191\n",
      "           4       0.76      0.57      0.65     11564\n",
      "           5       0.63      0.79      0.70      1828\n",
      "           6       0.36      0.68      0.47      1182\n",
      "           7       0.42      0.54      0.47      4877\n",
      "           8       0.73      0.43      0.54     23400\n",
      "           9       0.45      0.82      0.58      1740\n",
      "          10       0.44      0.70      0.54      4720\n",
      "          11       0.58      0.77      0.66      1748\n",
      "          12       0.57      0.72      0.63      1680\n",
      "          13       0.49      0.66      0.56      4573\n",
      "          14       0.59      0.63      0.61     13349\n",
      "\n",
      "    accuracy                           0.61     85300\n",
      "   macro avg       0.58      0.71      0.62     85300\n",
      "weighted avg       0.65      0.61      0.61     85300\n",
      "\n",
      "Accuracy:  0.6128722157092614 \n",
      "\n",
      "\n",
      "##############################################################################################################\n",
      "\n",
      "With sampling type: 3\n",
      "\n",
      "For training set\n",
      "\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.89      3511\n",
      "           1       0.89      0.89      0.89      3511\n",
      "           2       0.89      0.89      0.89      3511\n",
      "           3       0.90      0.92      0.91      3511\n",
      "           4       0.73      0.69      0.71      3511\n",
      "           5       0.93      0.90      0.91      3511\n",
      "           6       0.78      0.75      0.77      3511\n",
      "           7       0.67      0.65      0.66      3511\n",
      "           8       0.59      0.51      0.54      3511\n",
      "           9       0.87      0.90      0.89      3511\n",
      "          10       0.72      0.82      0.77      3511\n",
      "          11       0.90      0.86      0.88      3511\n",
      "          12       0.88      0.83      0.85      3511\n",
      "          13       0.77      0.79      0.78      3511\n",
      "          14       0.65      0.74      0.69      3511\n",
      "\n",
      "    accuracy                           0.80     52665\n",
      "   macro avg       0.80      0.80      0.80     52665\n",
      "weighted avg       0.80      0.80      0.80     52665\n",
      "\n",
      "Accuracy:  0.8038545523592519 \n",
      "\n",
      "\n",
      "\n",
      "For validation set\n",
      "\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.86      0.71      2923\n",
      "           1       0.47      0.83      0.60      1525\n",
      "           2       0.92      0.66      0.77      9280\n",
      "           3       0.52      0.87      0.66      1159\n",
      "           4       0.77      0.40      0.52     11539\n",
      "           5       0.32      0.84      0.47      1762\n",
      "           6       0.18      0.63      0.28      1087\n",
      "           7       0.33      0.54      0.41      4842\n",
      "           8       0.77      0.24      0.37     23492\n",
      "           9       0.32      0.87      0.47      1719\n",
      "          10       0.48      0.57      0.52      4753\n",
      "          11       0.39      0.80      0.52      1694\n",
      "          12       0.47      0.75      0.58      1794\n",
      "          13       0.35      0.76      0.48      4614\n",
      "          14       0.56      0.58      0.57     13117\n",
      "\n",
      "    accuracy                           0.52     85300\n",
      "   macro avg       0.50      0.68      0.53     85300\n",
      "weighted avg       0.64      0.52      0.51     85300\n",
      "\n",
      "Accuracy:  0.5150175849941383 \n",
      "\n",
      "\n",
      "\n",
      "For test set\n",
      "\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.84      0.70      2915\n",
      "           1       0.44      0.82      0.57      1450\n",
      "           2       0.92      0.67      0.77      9083\n",
      "           3       0.53      0.86      0.65      1191\n",
      "           4       0.76      0.39      0.52     11564\n",
      "           5       0.34      0.86      0.48      1828\n",
      "           6       0.20      0.65      0.31      1182\n",
      "           7       0.34      0.55      0.42      4877\n",
      "           8       0.77      0.24      0.37     23400\n",
      "           9       0.32      0.86      0.47      1740\n",
      "          10       0.48      0.55      0.51      4720\n",
      "          11       0.41      0.81      0.54      1748\n",
      "          12       0.44      0.72      0.55      1680\n",
      "          13       0.35      0.77      0.48      4573\n",
      "          14       0.57      0.59      0.58     13349\n",
      "\n",
      "    accuracy                           0.52     85300\n",
      "   macro avg       0.50      0.68      0.53     85300\n",
      "weighted avg       0.63      0.52      0.51     85300\n",
      "\n",
      "Accuracy:  0.5152286049237984 \n",
      "\n",
      "\n",
      "##############################################################################################################\n",
      "\n",
      "With sampling type: 6\n",
      "\n",
      "For training set\n",
      "\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.85      0.87      8623\n",
      "           1       0.86      0.75      0.80      4599\n",
      "           2       0.89      0.90      0.89     26950\n",
      "           3       0.85      0.79      0.82      3521\n",
      "           4       0.76      0.77      0.76     33860\n",
      "           5       0.93      0.75      0.83      5185\n",
      "           6       0.80      0.51      0.62      3511\n",
      "           7       0.72      0.57      0.64     14353\n",
      "           8       0.65      0.79      0.71     69267\n",
      "           9       0.82      0.68      0.75      5071\n",
      "          10       0.69      0.60      0.64     13874\n",
      "          11       0.86      0.69      0.76      5130\n",
      "          12       0.88      0.67      0.76      5137\n",
      "          13       0.71      0.62      0.66     13524\n",
      "          14       0.70      0.65      0.67     38948\n",
      "\n",
      "    accuracy                           0.73    251553\n",
      "   macro avg       0.80      0.71      0.75    251553\n",
      "weighted avg       0.74      0.73      0.73    251553\n",
      "\n",
      "Accuracy:  0.7349783147090275 \n",
      "\n",
      "\n",
      "\n",
      "For validation set\n",
      "\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.80      0.83      2923\n",
      "           1       0.82      0.66      0.73      1525\n",
      "           2       0.86      0.86      0.86      9280\n",
      "           3       0.80      0.74      0.77      1159\n",
      "           4       0.71      0.73      0.72     11539\n",
      "           5       0.91      0.68      0.78      1762\n",
      "           6       0.71      0.44      0.54      1087\n",
      "           7       0.63      0.48      0.54      4842\n",
      "           8       0.59      0.75      0.66     23492\n",
      "           9       0.75      0.58      0.66      1719\n",
      "          10       0.64      0.53      0.58      4753\n",
      "          11       0.80      0.62      0.70      1694\n",
      "          12       0.85      0.61      0.71      1794\n",
      "          13       0.63      0.54      0.58      4614\n",
      "          14       0.64      0.58      0.61     13117\n",
      "\n",
      "    accuracy                           0.68     85300\n",
      "   macro avg       0.75      0.64      0.68     85300\n",
      "weighted avg       0.69      0.68      0.68     85300\n",
      "\n",
      "Accuracy:  0.6786283704572098 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For test set\n",
      "\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.79      0.82      2915\n",
      "           1       0.81      0.68      0.74      1450\n",
      "           2       0.85      0.86      0.86      9083\n",
      "           3       0.79      0.73      0.76      1191\n",
      "           4       0.70      0.73      0.71     11564\n",
      "           5       0.90      0.69      0.78      1828\n",
      "           6       0.75      0.45      0.56      1182\n",
      "           7       0.63      0.49      0.55      4877\n",
      "           8       0.59      0.74      0.66     23400\n",
      "           9       0.76      0.57      0.65      1740\n",
      "          10       0.63      0.51      0.57      4720\n",
      "          11       0.81      0.63      0.71      1748\n",
      "          12       0.84      0.61      0.70      1680\n",
      "          13       0.63      0.55      0.59      4573\n",
      "          14       0.64      0.58      0.61     13349\n",
      "\n",
      "    accuracy                           0.68     85300\n",
      "   macro avg       0.75      0.64      0.68     85300\n",
      "weighted avg       0.68      0.68      0.68     85300\n",
      "\n",
      "Accuracy:  0.6763892145369285 \n",
      "\n",
      "\n",
      "##############################################################################################################\n",
      "\n",
      "Without any undersampling/oversampling\n",
      "\n",
      "For training set\n",
      "\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97     70439\n",
      "           1       0.97      0.98      0.97     70439\n",
      "           2       0.94      0.93      0.94     70439\n",
      "           3       0.98      0.99      0.98     70439\n",
      "           4       0.82      0.75      0.78     70439\n",
      "           5       0.96      0.96      0.96     70439\n",
      "           6       0.94      0.96      0.95     70439\n",
      "           7       0.83      0.81      0.82     70439\n",
      "           8       0.67      0.56      0.61     70439\n",
      "           9       0.95      0.97      0.96     70439\n",
      "          10       0.82      0.88      0.85     70439\n",
      "          11       0.96      0.97      0.96     70439\n",
      "          12       0.95      0.94      0.94     70439\n",
      "          13       0.85      0.87      0.86     70439\n",
      "          14       0.69      0.78      0.73     70439\n",
      "\n",
      "    accuracy                           0.89   1056585\n",
      "   macro avg       0.89      0.89      0.89   1056585\n",
      "weighted avg       0.89      0.89      0.89   1056585\n",
      "\n",
      "Accuracy:  0.8874212675743078 \n",
      "\n",
      "\n",
      "\n",
      "For validation set\n",
      "\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.85      0.81      2923\n",
      "           1       0.67      0.79      0.72      1525\n",
      "           2       0.87      0.84      0.86      9280\n",
      "           3       0.71      0.81      0.75      1159\n",
      "           4       0.75      0.62      0.68     11539\n",
      "           5       0.64      0.80      0.71      1762\n",
      "           6       0.40      0.61      0.48      1087\n",
      "           7       0.47      0.58      0.52      4842\n",
      "           8       0.71      0.52      0.60     23492\n",
      "           9       0.56      0.78      0.65      1719\n",
      "          10       0.49      0.68      0.57      4753\n",
      "          11       0.61      0.76      0.67      1694\n",
      "          12       0.56      0.75      0.64      1794\n",
      "          13       0.53      0.66      0.59      4614\n",
      "          14       0.57      0.62      0.59     13117\n",
      "\n",
      "    accuracy                           0.64     85300\n",
      "   macro avg       0.62      0.71      0.66     85300\n",
      "weighted avg       0.66      0.64      0.65     85300\n",
      "\n",
      "Accuracy:  0.6449237983587339 \n",
      "\n",
      "\n",
      "\n",
      "For test set\n",
      "\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.84      0.81      2915\n",
      "           1       0.66      0.79      0.72      1450\n",
      "           2       0.87      0.84      0.85      9083\n",
      "           3       0.71      0.80      0.75      1191\n",
      "           4       0.74      0.63      0.68     11564\n",
      "           5       0.65      0.81      0.72      1828\n",
      "           6       0.44      0.63      0.51      1182\n",
      "           7       0.46      0.59      0.52      4877\n",
      "           8       0.71      0.51      0.59     23400\n",
      "           9       0.57      0.78      0.66      1740\n",
      "          10       0.49      0.67      0.57      4720\n",
      "          11       0.62      0.76      0.68      1748\n",
      "          12       0.53      0.73      0.62      1680\n",
      "          13       0.53      0.66      0.59      4573\n",
      "          14       0.57      0.63      0.60     13349\n",
      "\n",
      "    accuracy                           0.64     85300\n",
      "   macro avg       0.62      0.71      0.66     85300\n",
      "weighted avg       0.66      0.64      0.65     85300\n",
      "\n",
      "Accuracy:  0.6441148886283704 \n",
      "\n",
      "\n",
      "##############################################################################################################\n",
      "\n",
      "With sampling type: 0\n",
      "\n",
      "For training set\n",
      "\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96     70439\n",
      "           1       0.95      0.98      0.97     70439\n",
      "           2       0.93      0.91      0.92     70439\n",
      "           3       0.96      0.99      0.98     70439\n",
      "           4       0.80      0.70      0.75     70439\n",
      "           5       0.96      0.98      0.97     70439\n",
      "           6       0.93      0.96      0.94     70439\n",
      "           7       0.81      0.78      0.79     70439\n",
      "           8       0.65      0.53      0.59     70439\n",
      "           9       0.93      0.97      0.95     70439\n",
      "          10       0.79      0.86      0.82     70439\n",
      "          11       0.94      0.97      0.95     70439\n",
      "          12       0.95      0.96      0.95     70439\n",
      "          13       0.82      0.85      0.83     70439\n",
      "          14       0.72      0.74      0.73     70439\n",
      "\n",
      "    accuracy                           0.88   1056585\n",
      "   macro avg       0.87      0.88      0.87   1056585\n",
      "weighted avg       0.87      0.88      0.87   1056585\n",
      "\n",
      "Accuracy:  0.8759683319373264 \n",
      "\n",
      "\n",
      "\n",
      "For validation set\n",
      "\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.87      0.80      2923\n",
      "           1       0.65      0.80      0.72      1525\n",
      "           2       0.86      0.85      0.86      9280\n",
      "           3       0.67      0.83      0.74      1159\n",
      "           4       0.75      0.61      0.67     11539\n",
      "           5       0.67      0.80      0.73      1762\n",
      "           6       0.38      0.64      0.47      1087\n",
      "           7       0.46      0.58      0.51      4842\n",
      "           8       0.73      0.49      0.59     23492\n",
      "           9       0.55      0.79      0.65      1719\n",
      "          10       0.47      0.72      0.57      4753\n",
      "          11       0.56      0.77      0.64      1694\n",
      "          12       0.59      0.74      0.66      1794\n",
      "          13       0.52      0.68      0.59      4614\n",
      "          14       0.61      0.64      0.62     13117\n",
      "\n",
      "    accuracy                           0.65     85300\n",
      "   macro avg       0.61      0.72      0.65     85300\n",
      "weighted avg       0.67      0.65      0.65     85300\n",
      "\n",
      "Accuracy:  0.6450879249706917 \n",
      "\n",
      "\n",
      "\n",
      "For test set\n",
      "\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.86      0.79      2915\n",
      "           1       0.62      0.81      0.71      1450\n",
      "           2       0.86      0.85      0.86      9083\n",
      "           3       0.67      0.82      0.74      1191\n",
      "           4       0.74      0.61      0.67     11564\n",
      "           5       0.69      0.81      0.75      1828\n",
      "           6       0.41      0.64      0.50      1182\n",
      "           7       0.46      0.59      0.52      4877\n",
      "           8       0.74      0.49      0.59     23400\n",
      "           9       0.54      0.80      0.65      1740\n",
      "          10       0.46      0.71      0.56      4720\n",
      "          11       0.59      0.78      0.67      1748\n",
      "          12       0.57      0.74      0.64      1680\n",
      "          13       0.51      0.68      0.58      4573\n",
      "          14       0.61      0.65      0.63     13349\n",
      "\n",
      "    accuracy                           0.64     85300\n",
      "   macro avg       0.61      0.72      0.66     85300\n",
      "weighted avg       0.67      0.64      0.64     85300\n",
      "\n",
      "Accuracy:  0.6447479484173505 \n",
      "\n",
      "\n",
      "##############################################################################################################\n",
      "\n",
      "With sampling type: 2\n",
      "\n",
      "For training set\n",
      "\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97     70439\n",
      "           1       0.97      0.98      0.97     70439\n",
      "           2       0.94      0.93      0.94     70439\n",
      "           3       0.97      0.99      0.98     70439\n",
      "           4       0.82      0.75      0.78     70439\n",
      "           5       0.96      0.96      0.96     70439\n",
      "           6       0.94      0.96      0.95     70439\n",
      "           7       0.83      0.81      0.82     70439\n",
      "           8       0.67      0.56      0.61     70439\n",
      "           9       0.94      0.97      0.96     70439\n",
      "          10       0.82      0.88      0.85     70439\n",
      "          11       0.96      0.97      0.96     70439\n",
      "          12       0.95      0.93      0.94     70439\n",
      "          13       0.85      0.87      0.86     70439\n",
      "          14       0.69      0.78      0.73     70439\n",
      "\n",
      "    accuracy                           0.89   1056585\n",
      "   macro avg       0.89      0.89      0.89   1056585\n",
      "weighted avg       0.89      0.89      0.89   1056585\n",
      "\n",
      "Accuracy:  0.887180870445823 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For validation set\n",
      "\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.85      0.81      2923\n",
      "           1       0.68      0.78      0.73      1525\n",
      "           2       0.87      0.84      0.86      9280\n",
      "           3       0.71      0.81      0.75      1159\n",
      "           4       0.75      0.63      0.68     11539\n",
      "           5       0.64      0.80      0.71      1762\n",
      "           6       0.39      0.60      0.47      1087\n",
      "           7       0.46      0.58      0.51      4842\n",
      "           8       0.71      0.51      0.60     23492\n",
      "           9       0.56      0.78      0.65      1719\n",
      "          10       0.49      0.68      0.57      4753\n",
      "          11       0.60      0.75      0.67      1694\n",
      "          12       0.57      0.75      0.64      1794\n",
      "          13       0.53      0.66      0.59      4614\n",
      "          14       0.57      0.62      0.59     13117\n",
      "\n",
      "    accuracy                           0.64     85300\n",
      "   macro avg       0.62      0.71      0.66     85300\n",
      "weighted avg       0.66      0.64      0.65     85300\n",
      "\n",
      "Accuracy:  0.6446776084407971 \n",
      "\n",
      "\n",
      "\n",
      "For test set\n",
      "\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.84      0.81      2915\n",
      "           1       0.66      0.79      0.72      1450\n",
      "           2       0.87      0.84      0.85      9083\n",
      "           3       0.71      0.80      0.75      1191\n",
      "           4       0.74      0.62      0.68     11564\n",
      "           5       0.65      0.81      0.72      1828\n",
      "           6       0.43      0.63      0.51      1182\n",
      "           7       0.46      0.59      0.52      4877\n",
      "           8       0.71      0.51      0.59     23400\n",
      "           9       0.57      0.78      0.66      1740\n",
      "          10       0.49      0.66      0.56      4720\n",
      "          11       0.62      0.77      0.69      1748\n",
      "          12       0.54      0.73      0.62      1680\n",
      "          13       0.53      0.67      0.59      4573\n",
      "          14       0.57      0.63      0.60     13349\n",
      "\n",
      "    accuracy                           0.64     85300\n",
      "   macro avg       0.62      0.71      0.66     85300\n",
      "weighted avg       0.66      0.64      0.64     85300\n",
      "\n",
      "Accuracy:  0.6434818288393904 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "X_tr, y_tr = X_train, y_train\n",
    "\n",
    "for _type in [1, 3, 6, -1, 0, 2]:\n",
    "    print('#'*110)\n",
    "    print()\n",
    "    if _type == -1:\n",
    "        print('Without any undersampling/oversampling')\n",
    "    else:\n",
    "        print(f'With sampling type: {_type}')\n",
    "    model = BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=15))\n",
    "    X_train, y_train = balance_data(X_tr, y_tr, _type)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    print()\n",
    "    print(\"For training set\")\n",
    "    print()\n",
    "    get_metrics(y_train, y_train_pred)\n",
    "\n",
    "    y_valid_pred = model.predict(X_valid)\n",
    "    print()\n",
    "    print(\"For validation set\")\n",
    "    print()\n",
    "    get_metrics(y_valid, y_valid_pred)\n",
    "\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    print()\n",
    "    print(\"For test set\")\n",
    "    print()\n",
    "    get_metrics(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32035fa",
   "metadata": {
    "id": "XxJyapqrhB9M",
    "papermill": {
     "duration": 0.014364,
     "end_time": "2021-10-26T18:24:41.839146",
     "exception": false,
     "start_time": "2021-10-26T18:24:41.824782",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Bagging One vs rest.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 97509.061898,
   "end_time": "2021-10-26T18:24:45.330442",
   "environment_variables": {},
   "exception": null,
   "input_path": "/home2/tgv2002/mrinal_IRE/IRE-Project-Team-7/Bagging_One_vs_rest.ipynb",
   "output_path": "/home2/tgv2002/mrinal_IRE/outputs/Baggin_decision_out.ipynb",
   "parameters": {},
   "start_time": "2021-10-25T15:19:36.268544",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
