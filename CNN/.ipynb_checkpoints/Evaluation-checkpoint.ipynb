{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "equal-taylor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "import pickle\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from nltk.corpus import stopwords\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dense, Input, GlobalMaxPooling1D, GlobalAveragePooling2D\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Embedding, Conv2D, MaxPooling2D, Dropout,concatenate\n",
    "from keras.layers.core import Reshape, Flatten\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import SGD, RMSprop, Adagrad, Adadelta, Adam, Adamax, Nadam\n",
    "from keras.models import Model, load_model\n",
    "from keras import regularizers\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models.keyedvectors import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "artificial-phenomenon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning data\n",
    "def clean_post(post):\n",
    "    post = post.lower()\n",
    "    post = re.sub(r\"\\n\", \" \", post)\n",
    "    post = re.sub(\"[\\<\\[].*?[\\>\\]]\", \" \", post)\n",
    "    post = re.sub(r\"[^a-z ]\", \" \", post)\n",
    "    post = re.sub(r\"\\b\\w{1,3}\\b\", \" \", post)\n",
    "    return \" \".join([x for x in post.split() if x not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "98a2d43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(ytrue, ypred):\n",
    "    y_true = np.argmax(ytrue, axis=1)\n",
    "    y_pred = np.argmax(ypred, axis=1)\n",
    "    result1 = classification_report(y_true, y_pred)\n",
    "    print('Classification Report: ', result1)\n",
    "    result2 = accuracy_score(y_true, y_pred)\n",
    "    print('Accuracy: ', result2, \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "daily-office",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_test_data():\n",
    "    # Load data\n",
    "    data = pd.read_csv('../split_data/test.csv')\n",
    "    data = shuffle(data)\n",
    "\n",
    "    # Class split stats\n",
    "    print(data.groupby(['mental_disorder'])[['mental_disorder']].describe())\n",
    "    X_test = data['post'].apply(lambda post: clean_post(post))\n",
    "    label_encoder = LabelEncoder()\n",
    "    y1 = label_encoder.fit_transform(np.array(data['mental_disorder']))\n",
    "    y_test = to_categorical(y1)\n",
    "    \n",
    "    # Load tokenizer\n",
    "    with open('../models/tokenizer.pkl', 'rb') as f:\n",
    "        tokenizer = pickle.load(f)\n",
    "\n",
    "    # Convert  texts to sequence of integers\n",
    "    sequences_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "    # Limit size of test sequences to 200 and pad the sequence\n",
    "    X_test = pad_sequences(sequences_test, maxlen=200)\n",
    "    print(f'Shape of X test tensor: {X_test.shape}')\n",
    "\n",
    "    # Convert target to array\n",
    "    y_test = np.asarray(y_test)\n",
    "    print(f'Shape of y test tensor: {y_test.shape}')\n",
    "    \n",
    "    # Evaluating\n",
    "    for _type in [1, 3, 5, 6, -1, 0, 2]:\n",
    "        model = load_model(f'../models/CNN_model_{_type}')\n",
    "        print('#'*110)\n",
    "        print()\n",
    "        if _type == -1:\n",
    "            print('Without any oversampling/undersampling')\n",
    "        else:\n",
    "            print(f'With sampling type: {_type}')\n",
    "        print()\n",
    "        print()\n",
    "        # Predict on test dataset\n",
    "        pred_test = model.predict(X_test)\n",
    "        get_metrics(y_test, pred_test)\n",
    "        print()\n",
    "        print()\n",
    "        print('#'*110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "68815199",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_label(text):\n",
    "    X_test = np.array([clean_post(text),])\n",
    "    \n",
    "    # Load tokenizer\n",
    "    with open('../models/tokenizer.pkl', 'rb') as f:\n",
    "        tokenizer = pickle.load(f)\n",
    "\n",
    "    # Convert  texts to sequence of integers\n",
    "    sequences_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "    # Limit size of test sequences to 200 and pad the sequence\n",
    "    X_test = pad_sequences(sequences_test, maxlen=200)\n",
    "    \n",
    "    # Evaluating\n",
    "    model = load_model(f'../models/CNN_model_6')\n",
    "    pred_test = model.predict(X_test)\n",
    "    return np.argmax(pred_test, axis=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecb2574",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_on_test_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
