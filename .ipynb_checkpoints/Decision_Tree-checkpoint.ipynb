{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cbf17b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-25T15:20:16.074679Z",
     "iopub.status.busy": "2021-10-25T15:20:16.074092Z",
     "iopub.status.idle": "2021-10-25T15:20:27.872244Z",
     "shell.execute_reply": "2021-10-25T15:20:27.872635Z"
    },
    "id": "Z1N9bc-Cf_m7",
    "papermill": {
     "duration": 11.817061,
     "end_time": "2021-10-25T15:20:27.872847",
     "exception": false,
     "start_time": "2021-10-25T15:20:16.055786",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "import nltk\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from nltk.corpus import stopwords\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models.keyedvectors import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4712a219",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-25T15:20:27.889656Z",
     "iopub.status.busy": "2021-10-25T15:20:27.889107Z",
     "iopub.status.idle": "2021-10-25T15:20:27.890888Z",
     "shell.execute_reply": "2021-10-25T15:20:27.891231Z"
    },
    "id": "hTEZ3LAngLCv",
    "papermill": {
     "duration": 0.011616,
     "end_time": "2021-10-25T15:20:27.891345",
     "exception": false,
     "start_time": "2021-10-25T15:20:27.879729",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_metrics(y_true, y_pred):\n",
    "    result1 = classification_report(y_true, y_pred)\n",
    "    print('Classification Report: ', result1)\n",
    "    result2 = accuracy_score(y_true, y_pred)\n",
    "    print('Accuracy: ', result2, \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41134bb0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-10-25T15:20:27.909772Z",
     "iopub.status.busy": "2021-10-25T15:20:27.909115Z",
     "iopub.status.idle": "2021-10-25T15:20:28.008386Z",
     "shell.execute_reply": "2021-10-25T15:20:28.008730Z"
    },
    "id": "uIvEjix7gQRj",
    "outputId": "1fb37836-6650-4b05-a81c-b40f99a853fe",
    "papermill": {
     "duration": 0.110145,
     "end_time": "2021-10-25T15:20:28.008866",
     "exception": false,
     "start_time": "2021-10-25T15:20:27.898721",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home2/tgv2002/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a34f3b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-25T15:20:28.026804Z",
     "iopub.status.busy": "2021-10-25T15:20:28.026237Z",
     "iopub.status.idle": "2021-10-25T15:20:28.030090Z",
     "shell.execute_reply": "2021-10-25T15:20:28.029713Z"
    },
    "id": "CX9H85mEgRn8",
    "papermill": {
     "duration": 0.014236,
     "end_time": "2021-10-25T15:20:28.030184",
     "exception": false,
     "start_time": "2021-10-25T15:20:28.015948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    " stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72e028e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-25T15:20:28.048012Z",
     "iopub.status.busy": "2021-10-25T15:20:28.047426Z",
     "iopub.status.idle": "2021-10-25T15:20:28.049585Z",
     "shell.execute_reply": "2021-10-25T15:20:28.049207Z"
    },
    "id": "LA6HfIqfgTNQ",
    "papermill": {
     "duration": 0.012777,
     "end_time": "2021-10-25T15:20:28.049678",
     "exception": false,
     "start_time": "2021-10-25T15:20:28.036901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_post(post):\n",
    "    post = post.lower()\n",
    "    post = re.sub(r\"\\n\", \" \", post)\n",
    "    post = re.sub(\"[\\<\\[].*?[\\>\\]]\", \" \", post)\n",
    "    post = re.sub(r\"[^a-z ]\", \" \", post)\n",
    "    post = re.sub(r\"\\b\\w{1,3}\\b\", \" \", post)\n",
    "    return \" \".join([x for x in post.split() if x not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e65d36a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-25T15:20:28.070450Z",
     "iopub.status.busy": "2021-10-25T15:20:28.069852Z",
     "iopub.status.idle": "2021-10-25T15:20:28.071588Z",
     "shell.execute_reply": "2021-10-25T15:20:28.071953Z"
    },
    "id": "71AR95q8gUqZ",
    "papermill": {
     "duration": 0.015656,
     "end_time": "2021-10-25T15:20:28.072094",
     "exception": false,
     "start_time": "2021-10-25T15:20:28.056438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler, TomekLinks, NearMiss, ClusterCentroids\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "def balance_data(x, y, _type):\n",
    "    if _type == 0:\n",
    "        ros = RandomOverSampler(random_state=42)\n",
    "        return ros.fit_resample(x, y)\n",
    "    elif _type == 1:\n",
    "        rus = RandomUnderSampler(random_state=42, replacement=True)\n",
    "        return rus.fit_resample(x, y)\n",
    "    elif _type == 2:\n",
    "        smote = SMOTE()\n",
    "        return smote.fit_resample(x, y)\n",
    "    elif _type == 3:\n",
    "        nm = NearMiss()\n",
    "        return nm.fit_resample(x, y)\n",
    "    elif _type == 4:\n",
    "        smt = SMOTETomek(ratio='auto')\n",
    "        return smt.fit_resample(x, y)\n",
    "    elif _type == 5:\n",
    "        cc = ClusterCentroids()\n",
    "        return cc.fit_resample(x, y)\n",
    "    elif _type == 6:\n",
    "        tl = TomekLinks()\n",
    "        return tl.fit_resample(x, y)\n",
    "\n",
    "    smote = SMOTE()\n",
    "    return smote.fit_resample(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1dbd487b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-10-25T15:20:28.116461Z",
     "iopub.status.busy": "2021-10-25T15:20:28.115946Z",
     "iopub.status.idle": "2021-10-25T15:21:31.504234Z",
     "shell.execute_reply": "2021-10-25T15:21:31.504611Z"
    },
    "id": "jFXVnznpgWKc",
    "outputId": "c18dc80e-3167-4c56-f9b4-185c3a84697e",
    "papermill": {
     "duration": 63.400369,
     "end_time": "2021-10-25T15:21:31.504753",
     "exception": false,
     "start_time": "2021-10-25T15:20:28.104384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                mental_disorder                              \n",
      "                          count unique            top    freq\n",
      "mental_disorder                                              \n",
      "EDAnonymous               14577      1    EDAnonymous   14577\n",
      "addiction                  7641      1      addiction    7641\n",
      "adhd                      45631      1           adhd   45631\n",
      "alcoholism                 5911      1     alcoholism    5911\n",
      "anxiety                   57671      1        anxiety   57671\n",
      "autism                     8869      1         autism    8869\n",
      "bipolarreddit              5780      1  bipolarreddit    5780\n",
      "bpd                       24294      1            bpd   24294\n",
      "depression               117331      1     depression  117331\n",
      "healthanxiety              8648      1  healthanxiety    8648\n",
      "lonely                    23635      1         lonely   23635\n",
      "ptsd                       8643      1           ptsd    8643\n",
      "schizophrenia              8712      1  schizophrenia    8712\n",
      "socialanxiety             22996      1  socialanxiety   22996\n",
      "suicidewatch              66161      1   suicidewatch   66161\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('/home2/tgv2002/reddit_mental_health_dataset/reddit_dataset.csv')\n",
    "data = shuffle(data)\n",
    "\n",
    "# Class split stats\n",
    "print(data.groupby(['mental_disorder'])[['mental_disorder']].describe())\n",
    "x = data['post'].apply(lambda post: clean_post(post))\n",
    "\n",
    "# Vectorizing text data\n",
    "count_vect = CountVectorizer()\n",
    "X_counts = count_vect.fit_transform(x)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X = tfidf_transformer.fit_transform(X_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbf0e273",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-25T15:21:31.526386Z",
     "iopub.status.busy": "2021-10-25T15:21:31.525641Z",
     "iopub.status.idle": "2021-10-25T15:21:31.811170Z",
     "shell.execute_reply": "2021-10-25T15:21:31.810777Z"
    },
    "id": "-223yjJBgXqP",
    "papermill": {
     "duration": 0.297749,
     "end_time": "2021-10-25T15:21:31.811282",
     "exception": false,
     "start_time": "2021-10-25T15:21:31.513533",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(np.array(data['mental_disorder']))\n",
    "# y = to_categorical(y1)\n",
    "\n",
    "# 60-20-20 split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=321)\n",
    "X_test, X_valid, y_test, y_valid = train_test_split(X_test, y_test, test_size=0.5, random_state=321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "443844c9",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-10-25T15:21:31.833123Z",
     "iopub.status.busy": "2021-10-25T15:21:31.832396Z",
     "iopub.status.idle": "2021-10-26T17:53:56.670281Z",
     "shell.execute_reply": "2021-10-26T17:53:56.670713Z"
    },
    "id": "D2ttwX1wge7y",
    "outputId": "4905873f-8936-459c-89e7-c31ed7b89100",
    "papermill": {
     "duration": 95544.851973,
     "end_time": "2021-10-26T17:53:56.670965",
     "exception": false,
     "start_time": "2021-10-25T15:21:31.818992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################################################################################################\n",
      "\n",
      "With sampling type: 1\n",
      "\n",
      "For training set\n",
      "\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91      3450\n",
      "           1       0.91      0.91      0.91      3450\n",
      "           2       0.90      0.90      0.90      3450\n",
      "           3       0.91      0.92      0.91      3450\n",
      "           4       0.76      0.71      0.73      3450\n",
      "           5       0.95      0.91      0.93      3450\n",
      "           6       0.89      0.83      0.86      3450\n",
      "           7       0.74      0.71      0.73      3450\n",
      "           8       0.69      0.62      0.65      3450\n",
      "           9       0.88      0.91      0.90      3450\n",
      "          10       0.75      0.84      0.80      3450\n",
      "          11       0.91      0.89      0.90      3450\n",
      "          12       0.91      0.88      0.89      3450\n",
      "          13       0.78      0.82      0.80      3450\n",
      "          14       0.69      0.77      0.73      3450\n",
      "\n",
      "    accuracy                           0.84     51750\n",
      "   macro avg       0.84      0.84      0.84     51750\n",
      "weighted avg       0.84      0.84      0.84     51750\n",
      "\n",
      "Accuracy:  0.8367149758454107 \n",
      "\n",
      "\n",
      "\n",
      "For validation set\n",
      "\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.86      0.72      2912\n",
      "           1       0.58      0.80      0.67      1503\n",
      "           2       0.85      0.81      0.83      9103\n",
      "           3       0.62      0.84      0.72      1223\n",
      "           4       0.76      0.56      0.65     11741\n",
      "           5       0.63      0.78      0.70      1820\n",
      "           6       0.38      0.64      0.47      1146\n",
      "           7       0.42      0.56      0.48      4836\n",
      "           8       0.73      0.43      0.54     23481\n",
      "           9       0.45      0.85      0.59      1678\n",
      "          10       0.44      0.71      0.54      4666\n",
      "          11       0.54      0.74      0.62      1717\n",
      "          12       0.56      0.73      0.63      1787\n",
      "          13       0.49      0.67      0.56      4521\n",
      "          14       0.58      0.63      0.60     13166\n",
      "\n",
      "    accuracy                           0.61     85300\n",
      "   macro avg       0.58      0.71      0.62     85300\n",
      "weighted avg       0.65      0.61      0.61     85300\n",
      "\n",
      "Accuracy:  0.6124970691676436 \n",
      "\n",
      "\n",
      "\n",
      "For test set\n",
      "\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.85      0.72      2885\n",
      "           1       0.59      0.80      0.68      1522\n",
      "           2       0.84      0.82      0.83      9018\n",
      "           3       0.61      0.87      0.72      1238\n",
      "           4       0.76      0.55      0.64     11485\n",
      "           5       0.63      0.79      0.70      1784\n",
      "           6       0.38      0.66      0.48      1151\n",
      "           7       0.42      0.55      0.48      4929\n",
      "           8       0.73      0.43      0.54     23507\n",
      "           9       0.45      0.83      0.58      1709\n",
      "          10       0.43      0.71      0.54      4721\n",
      "          11       0.55      0.77      0.64      1674\n",
      "          12       0.54      0.73      0.62      1736\n",
      "          13       0.50      0.66      0.57      4574\n",
      "          14       0.59      0.63      0.61     13367\n",
      "\n",
      "    accuracy                           0.61     85300\n",
      "   macro avg       0.58      0.71      0.62     85300\n",
      "weighted avg       0.65      0.61      0.61     85300\n",
      "\n",
      "Accuracy:  0.611957796014068 \n",
      "\n",
      "\n",
      "##############################################################################################################\n",
      "\n",
      "With sampling type: 3\n",
      "\n",
      "For training set\n",
      "\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89      3450\n",
      "           1       0.87      0.87      0.87      3450\n",
      "           2       0.85      0.86      0.86      3450\n",
      "           3       0.81      0.89      0.85      3450\n",
      "           4       0.74      0.69      0.72      3450\n",
      "           5       0.93      0.89      0.91      3450\n",
      "           6       0.89      0.81      0.84      3450\n",
      "           7       0.67      0.66      0.67      3450\n",
      "           8       0.59      0.52      0.55      3450\n",
      "           9       0.86      0.88      0.87      3450\n",
      "          10       0.70      0.81      0.75      3450\n",
      "          11       0.90      0.86      0.88      3450\n",
      "          12       0.88      0.83      0.85      3450\n",
      "          13       0.78      0.79      0.78      3450\n",
      "          14       0.63      0.70      0.67      3450\n",
      "\n",
      "    accuracy                           0.80     51750\n",
      "   macro avg       0.80      0.80      0.80     51750\n",
      "weighted avg       0.80      0.80      0.80     51750\n",
      "\n",
      "Accuracy:  0.797487922705314 \n",
      "\n",
      "\n",
      "\n",
      "For validation set\n",
      "\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.85      0.73      2912\n",
      "           1       0.62      0.78      0.69      1503\n",
      "           2       0.81      0.79      0.80      9103\n",
      "           3       0.71      0.80      0.75      1223\n",
      "           4       0.80      0.40      0.53     11741\n",
      "           5       0.42      0.84      0.56      1820\n",
      "           6       0.19      0.72      0.30      1146\n",
      "           7       0.31      0.56      0.40      4836\n",
      "           8       0.74      0.27      0.39     23481\n",
      "           9       0.37      0.86      0.52      1678\n",
      "          10       0.40      0.68      0.50      4666\n",
      "          11       0.44      0.77      0.56      1717\n",
      "          12       0.41      0.73      0.53      1787\n",
      "          13       0.39      0.72      0.51      4521\n",
      "          14       0.60      0.55      0.58     13166\n",
      "\n",
      "    accuracy                           0.53     85300\n",
      "   macro avg       0.52      0.69      0.56     85300\n",
      "weighted avg       0.63      0.53      0.53     85300\n",
      "\n",
      "Accuracy:  0.5340679953106682 \n",
      "\n",
      "\n",
      "\n",
      "For test set\n",
      "\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.84      0.72      2885\n",
      "           1       0.61      0.77      0.68      1522\n",
      "           2       0.81      0.80      0.80      9018\n",
      "           3       0.69      0.82      0.75      1238\n",
      "           4       0.80      0.40      0.53     11485\n",
      "           5       0.40      0.84      0.54      1784\n",
      "           6       0.19      0.71      0.30      1151\n",
      "           7       0.32      0.53      0.40      4929\n",
      "           8       0.73      0.27      0.39     23507\n",
      "           9       0.38      0.85      0.52      1709\n",
      "          10       0.40      0.68      0.50      4721\n",
      "          11       0.44      0.78      0.56      1674\n",
      "          12       0.40      0.74      0.52      1736\n",
      "          13       0.39      0.72      0.51      4574\n",
      "          14       0.60      0.53      0.56     13367\n",
      "\n",
      "    accuracy                           0.53     85300\n",
      "   macro avg       0.52      0.69      0.55     85300\n",
      "weighted avg       0.63      0.53      0.53     85300\n",
      "\n",
      "Accuracy:  0.5324736225087925 \n",
      "\n",
      "\n",
      "##############################################################################################################\n",
      "\n",
      "With sampling type: 6\n",
      "\n",
      "For training set\n",
      "\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.85      0.87      8662\n",
      "           1       0.86      0.75      0.80      4551\n",
      "           2       0.89      0.89      0.89     27207\n",
      "           3       0.85      0.80      0.82      3450\n",
      "           4       0.76      0.77      0.76     33743\n",
      "           5       0.93      0.75      0.83      5179\n",
      "           6       0.81      0.51      0.62      3409\n",
      "           7       0.72      0.56      0.63     14333\n",
      "           8       0.65      0.79      0.71     69165\n",
      "           9       0.83      0.68      0.74      5129\n",
      "          10       0.69      0.61      0.65     13938\n",
      "          11       0.85      0.68      0.76      5173\n",
      "          12       0.88      0.68      0.77      5094\n",
      "          13       0.72      0.63      0.67     13617\n",
      "          14       0.70      0.65      0.67     38913\n",
      "\n",
      "    accuracy                           0.74    251563\n",
      "   macro avg       0.80      0.71      0.75    251563\n",
      "weighted avg       0.74      0.74      0.73    251563\n",
      "\n",
      "Accuracy:  0.735298911207133 \n",
      "\n",
      "\n",
      "\n",
      "For validation set\n",
      "\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.79      0.82      2912\n",
      "           1       0.80      0.68      0.73      1503\n",
      "           2       0.85      0.86      0.86      9103\n",
      "           3       0.81      0.68      0.74      1223\n",
      "           4       0.71      0.72      0.71     11741\n",
      "           5       0.90      0.68      0.77      1820\n",
      "           6       0.74      0.42      0.53      1146\n",
      "           7       0.62      0.49      0.55      4836\n",
      "           8       0.59      0.74      0.65     23481\n",
      "           9       0.76      0.62      0.68      1678\n",
      "          10       0.62      0.53      0.57      4666\n",
      "          11       0.81      0.61      0.69      1717\n",
      "          12       0.85      0.61      0.71      1787\n",
      "          13       0.62      0.55      0.58      4521\n",
      "          14       0.64      0.58      0.61     13166\n",
      "\n",
      "    accuracy                           0.68     85300\n",
      "   macro avg       0.74      0.64      0.68     85300\n",
      "weighted avg       0.68      0.68      0.67     85300\n",
      "\n",
      "Accuracy:  0.6753692848769051 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For test set\n",
      "\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.79      0.82      2885\n",
      "           1       0.81      0.67      0.74      1522\n",
      "           2       0.85      0.87      0.86      9018\n",
      "           3       0.79      0.72      0.75      1238\n",
      "           4       0.71      0.72      0.71     11485\n",
      "           5       0.90      0.68      0.78      1784\n",
      "           6       0.73      0.42      0.54      1151\n",
      "           7       0.64      0.48      0.55      4929\n",
      "           8       0.59      0.74      0.66     23507\n",
      "           9       0.75      0.60      0.66      1709\n",
      "          10       0.61      0.54      0.57      4721\n",
      "          11       0.82      0.62      0.71      1674\n",
      "          12       0.85      0.61      0.71      1736\n",
      "          13       0.63      0.55      0.59      4574\n",
      "          14       0.64      0.57      0.60     13367\n",
      "\n",
      "    accuracy                           0.67     85300\n",
      "   macro avg       0.74      0.64      0.68     85300\n",
      "weighted avg       0.68      0.67      0.67     85300\n",
      "\n",
      "Accuracy:  0.6749706916764361 \n",
      "\n",
      "\n",
      "##############################################################################################################\n",
      "\n",
      "Without any undersampling/oversampling\n",
      "\n",
      "For training set\n",
      "\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97     70343\n",
      "           1       0.97      0.98      0.98     70343\n",
      "           2       0.94      0.93      0.93     70343\n",
      "           3       0.97      0.99      0.98     70343\n",
      "           4       0.83      0.75      0.78     70343\n",
      "           5       0.94      0.97      0.96     70343\n",
      "           6       0.95      0.96      0.95     70343\n",
      "           7       0.82      0.81      0.82     70343\n",
      "           8       0.67      0.56      0.61     70343\n",
      "           9       0.94      0.97      0.96     70343\n",
      "          10       0.82      0.88      0.85     70343\n",
      "          11       0.96      0.97      0.96     70343\n",
      "          12       0.96      0.96      0.96     70343\n",
      "          13       0.85      0.87      0.86     70343\n",
      "          14       0.71      0.75      0.73     70343\n",
      "\n",
      "    accuracy                           0.89   1055145\n",
      "   macro avg       0.89      0.89      0.89   1055145\n",
      "weighted avg       0.89      0.89      0.89   1055145\n",
      "\n",
      "Accuracy:  0.8883660539546697 \n",
      "\n",
      "\n",
      "\n",
      "For validation set\n",
      "\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.84      0.81      2912\n",
      "           1       0.66      0.80      0.72      1503\n",
      "           2       0.87      0.84      0.85      9103\n",
      "           3       0.73      0.78      0.75      1223\n",
      "           4       0.75      0.63      0.68     11741\n",
      "           5       0.58      0.80      0.68      1820\n",
      "           6       0.43      0.59      0.50      1146\n",
      "           7       0.45      0.59      0.51      4836\n",
      "           8       0.71      0.51      0.59     23481\n",
      "           9       0.56      0.80      0.66      1678\n",
      "          10       0.48      0.67      0.56      4666\n",
      "          11       0.59      0.73      0.65      1717\n",
      "          12       0.63      0.72      0.67      1787\n",
      "          13       0.52      0.66      0.58      4521\n",
      "          14       0.57      0.62      0.60     13166\n",
      "\n",
      "    accuracy                           0.64     85300\n",
      "   macro avg       0.62      0.71      0.65     85300\n",
      "weighted avg       0.66      0.64      0.64     85300\n",
      "\n",
      "Accuracy:  0.6425791324736225 \n",
      "\n",
      "\n",
      "\n",
      "For test set\n",
      "\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.84      0.80      2885\n",
      "           1       0.67      0.79      0.73      1522\n",
      "           2       0.87      0.84      0.85      9018\n",
      "           3       0.72      0.81      0.76      1238\n",
      "           4       0.74      0.62      0.68     11485\n",
      "           5       0.57      0.81      0.67      1784\n",
      "           6       0.42      0.60      0.50      1151\n",
      "           7       0.46      0.58      0.52      4929\n",
      "           8       0.71      0.51      0.59     23507\n",
      "           9       0.56      0.79      0.65      1709\n",
      "          10       0.48      0.67      0.56      4721\n",
      "          11       0.61      0.76      0.67      1674\n",
      "          12       0.63      0.73      0.67      1736\n",
      "          13       0.53      0.66      0.58      4574\n",
      "          14       0.57      0.62      0.59     13367\n",
      "\n",
      "    accuracy                           0.64     85300\n",
      "   macro avg       0.62      0.71      0.66     85300\n",
      "weighted avg       0.66      0.64      0.64     85300\n",
      "\n",
      "Accuracy:  0.6409964830011723 \n",
      "\n",
      "\n",
      "##############################################################################################################\n",
      "\n",
      "With sampling type: 0\n",
      "\n",
      "For training set\n",
      "\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96     70343\n",
      "           1       0.96      0.98      0.97     70343\n",
      "           2       0.93      0.91      0.92     70343\n",
      "           3       0.97      0.99      0.98     70343\n",
      "           4       0.81      0.70      0.75     70343\n",
      "           5       0.96      0.98      0.97     70343\n",
      "           6       0.93      0.96      0.95     70343\n",
      "           7       0.80      0.78      0.79     70343\n",
      "           8       0.65      0.53      0.59     70343\n",
      "           9       0.93      0.97      0.95     70343\n",
      "          10       0.79      0.86      0.82     70343\n",
      "          11       0.94      0.97      0.95     70343\n",
      "          12       0.94      0.96      0.95     70343\n",
      "          13       0.81      0.85      0.83     70343\n",
      "          14       0.73      0.74      0.73     70343\n",
      "\n",
      "    accuracy                           0.88   1055145\n",
      "   macro avg       0.87      0.88      0.87   1055145\n",
      "weighted avg       0.87      0.88      0.87   1055145\n",
      "\n",
      "Accuracy:  0.8768320941671524 \n",
      "\n",
      "\n",
      "\n",
      "For validation set\n",
      "\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.86      0.79      2912\n",
      "           1       0.63      0.81      0.71      1503\n",
      "           2       0.86      0.84      0.85      9103\n",
      "           3       0.70      0.80      0.75      1223\n",
      "           4       0.75      0.61      0.68     11741\n",
      "           5       0.68      0.80      0.74      1820\n",
      "           6       0.40      0.62      0.49      1146\n",
      "           7       0.46      0.60      0.52      4836\n",
      "           8       0.74      0.49      0.58     23481\n",
      "           9       0.54      0.82      0.65      1678\n",
      "          10       0.45      0.70      0.55      4666\n",
      "          11       0.56      0.76      0.64      1717\n",
      "          12       0.59      0.74      0.66      1787\n",
      "          13       0.51      0.68      0.59      4521\n",
      "          14       0.61      0.65      0.63     13166\n",
      "\n",
      "    accuracy                           0.64     85300\n",
      "   macro avg       0.61      0.72      0.65     85300\n",
      "weighted avg       0.67      0.64      0.64     85300\n",
      "\n",
      "Accuracy:  0.6442907385697538 \n",
      "\n",
      "\n",
      "\n",
      "For test set\n",
      "\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.86      0.78      2885\n",
      "           1       0.64      0.81      0.71      1522\n",
      "           2       0.86      0.85      0.85      9018\n",
      "           3       0.69      0.83      0.75      1238\n",
      "           4       0.75      0.61      0.67     11485\n",
      "           5       0.69      0.80      0.74      1784\n",
      "           6       0.41      0.63      0.49      1151\n",
      "           7       0.47      0.59      0.52      4929\n",
      "           8       0.73      0.49      0.59     23507\n",
      "           9       0.54      0.82      0.65      1709\n",
      "          10       0.46      0.71      0.56      4721\n",
      "          11       0.57      0.78      0.66      1674\n",
      "          12       0.58      0.75      0.66      1736\n",
      "          13       0.52      0.67      0.58      4574\n",
      "          14       0.61      0.64      0.62     13367\n",
      "\n",
      "    accuracy                           0.64     85300\n",
      "   macro avg       0.61      0.72      0.66     85300\n",
      "weighted avg       0.67      0.64      0.64     85300\n",
      "\n",
      "Accuracy:  0.6432942555685814 \n",
      "\n",
      "\n",
      "##############################################################################################################\n",
      "\n",
      "With sampling type: 2\n",
      "\n",
      "For training set\n",
      "\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97     70343\n",
      "           1       0.97      0.98      0.98     70343\n",
      "           2       0.94      0.92      0.93     70343\n",
      "           3       0.97      0.99      0.98     70343\n",
      "           4       0.82      0.75      0.78     70343\n",
      "           5       0.94      0.97      0.96     70343\n",
      "           6       0.95      0.96      0.95     70343\n",
      "           7       0.82      0.81      0.82     70343\n",
      "           8       0.67      0.56      0.61     70343\n",
      "           9       0.94      0.97      0.96     70343\n",
      "          10       0.82      0.88      0.85     70343\n",
      "          11       0.96      0.97      0.96     70343\n",
      "          12       0.96      0.96      0.96     70343\n",
      "          13       0.85      0.87      0.86     70343\n",
      "          14       0.71      0.76      0.74     70343\n",
      "\n",
      "    accuracy                           0.89   1055145\n",
      "   macro avg       0.89      0.89      0.89   1055145\n",
      "weighted avg       0.89      0.89      0.89   1055145\n",
      "\n",
      "Accuracy:  0.8885176918812107 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For validation set\n",
      "\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.84      0.80      2912\n",
      "           1       0.66      0.80      0.72      1503\n",
      "           2       0.87      0.84      0.85      9103\n",
      "           3       0.73      0.78      0.75      1223\n",
      "           4       0.75      0.63      0.68     11741\n",
      "           5       0.58      0.81      0.68      1820\n",
      "           6       0.43      0.59      0.50      1146\n",
      "           7       0.45      0.60      0.51      4836\n",
      "           8       0.71      0.51      0.60     23481\n",
      "           9       0.57      0.80      0.66      1678\n",
      "          10       0.48      0.66      0.56      4666\n",
      "          11       0.60      0.74      0.66      1717\n",
      "          12       0.63      0.72      0.67      1787\n",
      "          13       0.52      0.66      0.58      4521\n",
      "          14       0.57      0.62      0.60     13166\n",
      "\n",
      "    accuracy                           0.64     85300\n",
      "   macro avg       0.62      0.71      0.66     85300\n",
      "weighted avg       0.66      0.64      0.64     85300\n",
      "\n",
      "Accuracy:  0.6426611957796015 \n",
      "\n",
      "\n",
      "\n",
      "For test set\n",
      "\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.83      0.80      2885\n",
      "           1       0.67      0.79      0.73      1522\n",
      "           2       0.87      0.84      0.86      9018\n",
      "           3       0.72      0.81      0.76      1238\n",
      "           4       0.74      0.62      0.67     11485\n",
      "           5       0.57      0.82      0.67      1784\n",
      "           6       0.43      0.61      0.51      1151\n",
      "           7       0.47      0.58      0.52      4929\n",
      "           8       0.71      0.51      0.60     23507\n",
      "           9       0.56      0.80      0.66      1709\n",
      "          10       0.48      0.68      0.56      4721\n",
      "          11       0.61      0.76      0.68      1674\n",
      "          12       0.62      0.73      0.67      1736\n",
      "          13       0.53      0.66      0.59      4574\n",
      "          14       0.57      0.62      0.59     13367\n",
      "\n",
      "    accuracy                           0.64     85300\n",
      "   macro avg       0.62      0.71      0.66     85300\n",
      "weighted avg       0.66      0.64      0.64     85300\n",
      "\n",
      "Accuracy:  0.6417584994138336 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "X_tr, y_tr = X_train, y_train\n",
    "\n",
    "for _type in [1, 3, 6, -1, 0, 2]:\n",
    "    print('#'*110)\n",
    "    print()\n",
    "    if _type == -1:\n",
    "        print('Without any undersampling/oversampling')\n",
    "    else:\n",
    "        print(f'With sampling type: {_type}')\n",
    "    model = BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=15))\n",
    "    X_train, y_train = balance_data(X_tr, y_tr, _type)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    print()\n",
    "    print(\"For training set\")\n",
    "    print()\n",
    "    get_metrics(y_train, y_train_pred)\n",
    "\n",
    "    y_valid_pred = model.predict(X_valid)\n",
    "    print()\n",
    "    print(\"For validation set\")\n",
    "    print()\n",
    "    get_metrics(y_valid, y_valid_pred)\n",
    "\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    print()\n",
    "    print(\"For test set\")\n",
    "    print()\n",
    "    get_metrics(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fd3729",
   "metadata": {
    "id": "XxJyapqrhB9M",
    "papermill": {
     "duration": 0.013313,
     "end_time": "2021-10-26T17:53:56.699387",
     "exception": false,
     "start_time": "2021-10-26T17:53:56.686074",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Bagging One vs rest.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 95625.865244,
   "end_time": "2021-10-26T17:53:59.726651",
   "environment_variables": {},
   "exception": null,
   "input_path": "/home2/tgv2002/mrinal_IRE/IRE-Project-Team-7/Bagging_One_vs_rest.ipynb",
   "output_path": "/home2/tgv2002/mrinal_IRE/outputs/decision.ipynb",
   "parameters": {},
   "start_time": "2021-10-25T15:20:13.861407",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
