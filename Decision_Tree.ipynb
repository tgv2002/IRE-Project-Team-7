{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Decision Tree.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KE1bmFxTlQkm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6473572-a038-4d12-f525-4c5e78c585ce"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import re\n",
        "import nltk\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from nltk.corpus import stopwords\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models.keyedvectors import KeyedVectors"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDJii2kSlW2p"
      },
      "source": [
        "def get_metrics(y_true, y_pred):\n",
        "    result1 = classification_report(y_true, y_pred)\n",
        "    print('Classification Report: ', result1)\n",
        "    result2 = accuracy_score(y_true, y_pred)\n",
        "    print('Accuracy: ', result2, \"\\n\\n\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7NCIuYdlXjU",
        "outputId": "72849e7a-deed-4a25-ceb2-fd855333d7bb"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0xNf_JylZhf"
      },
      "source": [
        "stop_words = set(stopwords.words('english'))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBlwcEcBlbd4"
      },
      "source": [
        "def clean_post(post):\n",
        "  post = post.lower()\n",
        "  post = re.sub(r\"\\n\", \" \", post)\n",
        "  post = re.sub(\"[\\<\\[].*?[\\>\\]]\", \" \", post)\n",
        "  post = re.sub(r\"[^a-z ]\", \" \", post)\n",
        "  post = re.sub(r\"\\b\\w{1,3}\\b\", \" \", post)\n",
        "  return \" \".join([x for x in post.split() if x not in stop_words])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsZUt4xwldhR"
      },
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler, TomekLinks, NearMiss, ClusterCentroids\n",
        "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
        "from imblearn.combine import SMOTETomek\n",
        "\n",
        "def balance_data(x, y, _type):\n",
        "  if _type == 0:\n",
        "    ros = RandomOverSampler(random_state=42)\n",
        "    return ros.fit_resample(x, y)\n",
        "  elif _type == 1:\n",
        "    rus = RandomUnderSampler(random_state=42, replacement=True)\n",
        "    return rus.fit_resample(x, y)\n",
        "  elif _type == 2:\n",
        "    smote = SMOTE()\n",
        "    return smote.fit_resample(x, y)\n",
        "  elif _type == 3:\n",
        "    nm = NearMiss()\n",
        "    return nm.fit_resample(x, y)\n",
        "  elif _type == 4:\n",
        "    smt = SMOTETomek(ratio='auto')\n",
        "    return smt.fit_resample(x, y)\n",
        "  elif _type == 5:\n",
        "    cc = ClusterCentroids()\n",
        "    return cc.fit_resample(x, y)\n",
        "  elif _type == 6:\n",
        "    tl = TomekLinks()\n",
        "    return tl.fit_resample(x, y)\n",
        "  # default\n",
        "  smote = SMOTE()\n",
        "  return smote.fit_resample(x, y)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_QbTHjEnspO",
        "outputId": "57663484-807b-4169-d768-4a0c4de547c9"
      },
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/reddit_dataset.csv')\n",
        "data = shuffle(data)\n",
        "\n",
        "# Class split stats\n",
        "print(data.groupby(['mental_disorder'])[['mental_disorder']].describe())\n",
        "x = data['post'].apply(lambda post: clean_post(post))\n",
        "\n",
        "# Vectorizing text data\n",
        "count_vect = CountVectorizer()\n",
        "X_counts = count_vect.fit_transform(x)\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "X = tfidf_transformer.fit_transform(X_counts)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                mental_disorder                              \n",
            "                          count unique            top    freq\n",
            "mental_disorder                                              \n",
            "EDAnonymous               14577      1    EDAnonymous   14577\n",
            "addiction                  7641      1      addiction    7641\n",
            "adhd                      45631      1           adhd   45631\n",
            "alcoholism                 5911      1     alcoholism    5911\n",
            "anxiety                   57671      1        anxiety   57671\n",
            "autism                     8869      1         autism    8869\n",
            "bipolarreddit              5780      1  bipolarreddit    5780\n",
            "bpd                       24294      1            bpd   24294\n",
            "depression               117331      1     depression  117331\n",
            "healthanxiety              8648      1  healthanxiety    8648\n",
            "lonely                    23635      1         lonely   23635\n",
            "ptsd                       8643      1           ptsd    8643\n",
            "schizophrenia              8712      1  schizophrenia    8712\n",
            "socialanxiety             22996      1  socialanxiety   22996\n",
            "suicidewatch              66161      1   suicidewatch   66161\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WQkS8Bfnvz0"
      },
      "source": [
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(np.array(data['mental_disorder']))\n",
        "# y = to_categorical(y1)\n",
        "\n",
        "# 60-20-20 split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=321)\n",
        "X_test, X_valid, y_test, y_valid = train_test_split(X_test, y_test, test_size=0.5, random_state=321)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zi2xvekepBvC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca58774a-41f7-4098-ec19-90edbd45f684"
      },
      "source": [
        "import gc\n",
        "\n",
        "X_tr, y_tr = X_train, y_train\n",
        "\n",
        "for _type in [1,-1]:\n",
        "  print('#'*110)\n",
        "  print()\n",
        "  if _type == -1:\n",
        "    print('Without any undersampling/oversampling')\n",
        "  else:\n",
        "    print(f'With sampling type: {_type}')\n",
        "  model = DecisionTreeClassifier(max_depth=13, random_state=321)\n",
        "  X_train, y_train = balance_data(X_tr, y_tr, _type)\n",
        "  model.fit(X_train, y_train)\n",
        "\n",
        "  y_train_pred = model.predict(X_train)\n",
        "  print()\n",
        "  print(\"For training set\")\n",
        "  print()\n",
        "  get_metrics(y_train, y_train_pred)\n",
        "\n",
        "  y_valid_pred = model.predict(X_valid)\n",
        "  print()\n",
        "  print(\"For validation set\")\n",
        "  print()\n",
        "  get_metrics(y_valid, y_valid_pred)\n",
        "\n",
        "  y_test_pred = model.predict(X_test)\n",
        "  print()\n",
        "  print(\"For test set\")\n",
        "  print()\n",
        "  get_metrics(y_test, y_test_pred)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##############################################################################################################\n",
            "\n",
            "With sampling type: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "For training set\n",
            "\n",
            "Classification Report:                precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.58      0.64      3487\n",
            "           1       0.90      0.43      0.58      3487\n",
            "           2       0.91      0.52      0.66      3487\n",
            "           3       0.75      0.65      0.70      3487\n",
            "           4       0.44      0.59      0.50      3487\n",
            "           5       0.99      0.63      0.77      3487\n",
            "           6       0.78      0.36      0.49      3487\n",
            "           7       0.64      0.06      0.11      3487\n",
            "           8       0.56      0.04      0.07      3487\n",
            "           9       0.88      0.30      0.45      3487\n",
            "          10       0.80      0.39      0.53      3487\n",
            "          11       0.93      0.62      0.74      3487\n",
            "          12       0.97      0.38      0.55      3487\n",
            "          13       0.79      0.36      0.50      3487\n",
            "          14       0.12      0.89      0.21      3487\n",
            "\n",
            "    accuracy                           0.45     52305\n",
            "   macro avg       0.75      0.45      0.50     52305\n",
            "weighted avg       0.75      0.45      0.50     52305\n",
            "\n",
            "Accuracy:  0.45353216709683586 \n",
            "\n",
            "\n",
            "\n",
            "For validation set\n",
            "\n",
            "Classification Report:                precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.44      0.45      2864\n",
            "           1       0.54      0.39      0.45      1542\n",
            "           2       0.91      0.48      0.63      9101\n",
            "           3       0.35      0.62      0.45      1187\n",
            "           4       0.59      0.52      0.55     11574\n",
            "           5       0.74      0.60      0.66      1815\n",
            "           6       0.40      0.31      0.35      1123\n",
            "           7       0.12      0.01      0.02      4892\n",
            "           8       0.49      0.01      0.01     23402\n",
            "           9       0.39      0.29      0.33      1812\n",
            "          10       0.52      0.28      0.36      4640\n",
            "          11       0.56      0.51      0.54      1705\n",
            "          12       0.79      0.34      0.47      1797\n",
            "          13       0.51      0.34      0.41      4624\n",
            "          14       0.21      0.84      0.34     13222\n",
            "\n",
            "    accuracy                           0.36     85300\n",
            "   macro avg       0.51      0.40      0.40     85300\n",
            "weighted avg       0.50      0.36      0.32     85300\n",
            "\n",
            "Accuracy:  0.3588159437280188 \n",
            "\n",
            "\n",
            "\n",
            "For test set\n",
            "\n",
            "Classification Report:                precision    recall  f1-score   support\n",
            "\n",
            "           0       0.43      0.40      0.41      2869\n",
            "           1       0.54      0.38      0.45      1526\n",
            "           2       0.92      0.49      0.64      9083\n",
            "           3       0.34      0.59      0.43      1166\n",
            "           4       0.58      0.51      0.55     11509\n",
            "           5       0.72      0.60      0.66      1723\n",
            "           6       0.41      0.32      0.36      1170\n",
            "           7       0.14      0.01      0.02      4889\n",
            "           8       0.44      0.01      0.01     23539\n",
            "           9       0.35      0.27      0.30      1722\n",
            "          10       0.54      0.29      0.38      4790\n",
            "          11       0.60      0.54      0.57      1733\n",
            "          12       0.78      0.35      0.48      1660\n",
            "          13       0.49      0.33      0.39      4636\n",
            "          14       0.21      0.83      0.34     13285\n",
            "\n",
            "    accuracy                           0.36     85300\n",
            "   macro avg       0.50      0.40      0.40     85300\n",
            "weighted avg       0.48      0.36      0.31     85300\n",
            "\n",
            "Accuracy:  0.3564361078546307 \n",
            "\n",
            "\n",
            "##############################################################################################################\n",
            "\n",
            "Without any undersampling/oversampling\n",
            "\n",
            "For training set\n",
            "\n",
            "Classification Report:                precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.59      0.65      3487\n",
            "           1       0.90      0.42      0.57      3487\n",
            "           2       0.91      0.52      0.66      3487\n",
            "           3       0.73      0.66      0.69      3487\n",
            "           4       0.50      0.53      0.51      3487\n",
            "           5       0.98      0.62      0.76      3487\n",
            "           6       0.77      0.35      0.48      3487\n",
            "           7       0.78      0.04      0.08      3487\n",
            "           8       0.36      0.06      0.10      3487\n",
            "           9       0.88      0.29      0.43      3487\n",
            "          10       0.76      0.41      0.53      3487\n",
            "          11       0.92      0.61      0.74      3487\n",
            "          12       0.96      0.38      0.54      3487\n",
            "          13       0.81      0.35      0.49      3487\n",
            "          14       0.12      0.90      0.21      3487\n",
            "\n",
            "    accuracy                           0.45     52305\n",
            "   macro avg       0.74      0.45      0.50     52305\n",
            "weighted avg       0.74      0.45      0.50     52305\n",
            "\n",
            "Accuracy:  0.4486569161648026 \n",
            "\n",
            "\n",
            "\n",
            "For validation set\n",
            "\n",
            "Classification Report:                precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.45      0.45      2864\n",
            "           1       0.54      0.38      0.45      1542\n",
            "           2       0.92      0.48      0.63      9101\n",
            "           3       0.36      0.65      0.46      1187\n",
            "           4       0.70      0.46      0.55     11574\n",
            "           5       0.74      0.60      0.67      1815\n",
            "           6       0.40      0.32      0.36      1123\n",
            "           7       0.14      0.01      0.01      4892\n",
            "           8       0.55      0.04      0.07     23402\n",
            "           9       0.36      0.26      0.30      1812\n",
            "          10       0.50      0.30      0.38      4640\n",
            "          11       0.58      0.51      0.54      1705\n",
            "          12       0.79      0.33      0.47      1797\n",
            "          13       0.53      0.31      0.39      4624\n",
            "          14       0.21      0.85      0.34     13222\n",
            "\n",
            "    accuracy                           0.36     85300\n",
            "   macro avg       0.52      0.40      0.40     85300\n",
            "weighted avg       0.53      0.36      0.33     85300\n",
            "\n",
            "Accuracy:  0.3596483001172333 \n",
            "\n",
            "\n",
            "\n",
            "For test set\n",
            "\n",
            "Classification Report:                precision    recall  f1-score   support\n",
            "\n",
            "           0       0.43      0.41      0.42      2869\n",
            "           1       0.54      0.37      0.44      1526\n",
            "           2       0.93      0.49      0.64      9083\n",
            "           3       0.33      0.61      0.43      1166\n",
            "           4       0.69      0.45      0.55     11509\n",
            "           5       0.73      0.61      0.66      1723\n",
            "           6       0.41      0.33      0.36      1170\n",
            "           7       0.14      0.01      0.01      4889\n",
            "           8       0.53      0.04      0.07     23539\n",
            "           9       0.34      0.25      0.29      1722\n",
            "          10       0.51      0.31      0.39      4790\n",
            "          11       0.62      0.54      0.58      1733\n",
            "          12       0.77      0.35      0.48      1660\n",
            "          13       0.52      0.30      0.38      4636\n",
            "          14       0.21      0.85      0.34     13285\n",
            "\n",
            "    accuracy                           0.36     85300\n",
            "   macro avg       0.51      0.39      0.40     85300\n",
            "weighted avg       0.52      0.36      0.33     85300\n",
            "\n",
            "Accuracy:  0.35781946072684645 \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-FNVIf8xwHd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}