{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f6b3d1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-25T15:17:40.977238Z",
     "iopub.status.busy": "2021-10-25T15:17:40.976717Z",
     "iopub.status.idle": "2021-10-25T15:17:55.896111Z",
     "shell.execute_reply": "2021-10-25T15:17:55.896510Z"
    },
    "id": "Z1N9bc-Cf_m7",
    "papermill": {
     "duration": 14.936676,
     "end_time": "2021-10-25T15:17:55.896720",
     "exception": false,
     "start_time": "2021-10-25T15:17:40.960044",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "import nltk\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from nltk.corpus import stopwords\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models.keyedvectors import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17289d45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-25T15:17:55.915675Z",
     "iopub.status.busy": "2021-10-25T15:17:55.915216Z",
     "iopub.status.idle": "2021-10-25T15:17:55.917335Z",
     "shell.execute_reply": "2021-10-25T15:17:55.916919Z"
    },
    "id": "hTEZ3LAngLCv",
    "papermill": {
     "duration": 0.013157,
     "end_time": "2021-10-25T15:17:55.917426",
     "exception": false,
     "start_time": "2021-10-25T15:17:55.904269",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_metrics(y_true, y_pred):\n",
    "    result1 = classification_report(y_true, y_pred)\n",
    "    print('Classification Report: ', result1)\n",
    "    result2 = accuracy_score(y_true, y_pred)\n",
    "    print('Accuracy: ', result2, \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf214730",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-10-25T15:17:55.934954Z",
     "iopub.status.busy": "2021-10-25T15:17:55.934460Z",
     "iopub.status.idle": "2021-10-25T15:17:56.037470Z",
     "shell.execute_reply": "2021-10-25T15:17:56.037855Z"
    },
    "id": "uIvEjix7gQRj",
    "outputId": "1fb37836-6650-4b05-a81c-b40f99a853fe",
    "papermill": {
     "duration": 0.114296,
     "end_time": "2021-10-25T15:17:56.037963",
     "exception": false,
     "start_time": "2021-10-25T15:17:55.923667",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home2/tgv2002/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "975441a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-25T15:17:56.056436Z",
     "iopub.status.busy": "2021-10-25T15:17:56.055739Z",
     "iopub.status.idle": "2021-10-25T15:17:56.069626Z",
     "shell.execute_reply": "2021-10-25T15:17:56.069223Z"
    },
    "id": "CX9H85mEgRn8",
    "papermill": {
     "duration": 0.024223,
     "end_time": "2021-10-25T15:17:56.069721",
     "exception": false,
     "start_time": "2021-10-25T15:17:56.045498",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    " stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2f5b850",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-25T15:17:56.088994Z",
     "iopub.status.busy": "2021-10-25T15:17:56.088407Z",
     "iopub.status.idle": "2021-10-25T15:17:56.090494Z",
     "shell.execute_reply": "2021-10-25T15:17:56.090105Z"
    },
    "id": "LA6HfIqfgTNQ",
    "papermill": {
     "duration": 0.013402,
     "end_time": "2021-10-25T15:17:56.090583",
     "exception": false,
     "start_time": "2021-10-25T15:17:56.077181",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_post(post):\n",
    "    post = post.lower()\n",
    "    post = re.sub(r\"\\n\", \" \", post)\n",
    "    post = re.sub(\"[\\<\\[].*?[\\>\\]]\", \" \", post)\n",
    "    post = re.sub(r\"[^a-z ]\", \" \", post)\n",
    "    post = re.sub(r\"\\b\\w{1,3}\\b\", \" \", post)\n",
    "    return \" \".join([x for x in post.split() if x not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1141529",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-25T15:17:56.136088Z",
     "iopub.status.busy": "2021-10-25T15:17:56.135522Z",
     "iopub.status.idle": "2021-10-25T15:17:56.137289Z",
     "shell.execute_reply": "2021-10-25T15:17:56.137669Z"
    },
    "id": "71AR95q8gUqZ",
    "papermill": {
     "duration": 0.039736,
     "end_time": "2021-10-25T15:17:56.137781",
     "exception": false,
     "start_time": "2021-10-25T15:17:56.098045",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler, TomekLinks, NearMiss, ClusterCentroids\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "def balance_data(x, y, _type):\n",
    "    if _type == 0:\n",
    "        ros = RandomOverSampler(random_state=42)\n",
    "        return ros.fit_resample(x, y)\n",
    "    elif _type == 1:\n",
    "        rus = RandomUnderSampler(random_state=42, replacement=True)\n",
    "        return rus.fit_resample(x, y)\n",
    "    elif _type == 2:\n",
    "        smote = SMOTE()\n",
    "        return smote.fit_resample(x, y)\n",
    "    elif _type == 3:\n",
    "        nm = NearMiss()\n",
    "        return nm.fit_resample(x, y)\n",
    "    elif _type == 4:\n",
    "        smt = SMOTETomek(ratio='auto')\n",
    "        return smt.fit_resample(x, y)\n",
    "    elif _type == 5:\n",
    "        cc = ClusterCentroids()\n",
    "        return cc.fit_resample(x, y)\n",
    "    elif _type == 6:\n",
    "        tl = TomekLinks()\n",
    "        return tl.fit_resample(x, y)\n",
    "\n",
    "    smote = SMOTE()\n",
    "    return smote.fit_resample(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3965bfb2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-10-25T15:17:56.157564Z",
     "iopub.status.busy": "2021-10-25T15:17:56.155029Z",
     "iopub.status.idle": "2021-10-25T15:18:59.056340Z",
     "shell.execute_reply": "2021-10-25T15:18:59.056728Z"
    },
    "id": "jFXVnznpgWKc",
    "outputId": "c18dc80e-3167-4c56-f9b4-185c3a84697e",
    "papermill": {
     "duration": 62.91098,
     "end_time": "2021-10-25T15:18:59.056864",
     "exception": false,
     "start_time": "2021-10-25T15:17:56.145884",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                mental_disorder                              \n",
      "                          count unique            top    freq\n",
      "mental_disorder                                              \n",
      "EDAnonymous               14577      1    EDAnonymous   14577\n",
      "addiction                  7641      1      addiction    7641\n",
      "adhd                      45631      1           adhd   45631\n",
      "alcoholism                 5911      1     alcoholism    5911\n",
      "anxiety                   57671      1        anxiety   57671\n",
      "autism                     8869      1         autism    8869\n",
      "bipolarreddit              5780      1  bipolarreddit    5780\n",
      "bpd                       24294      1            bpd   24294\n",
      "depression               117331      1     depression  117331\n",
      "healthanxiety              8648      1  healthanxiety    8648\n",
      "lonely                    23635      1         lonely   23635\n",
      "ptsd                       8643      1           ptsd    8643\n",
      "schizophrenia              8712      1  schizophrenia    8712\n",
      "socialanxiety             22996      1  socialanxiety   22996\n",
      "suicidewatch              66161      1   suicidewatch   66161\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('/home2/tgv2002/reddit_mental_health_dataset/reddit_dataset.csv')\n",
    "data = shuffle(data)\n",
    "\n",
    "# Class split stats\n",
    "print(data.groupby(['mental_disorder'])[['mental_disorder']].describe())\n",
    "x = data['post'].apply(lambda post: clean_post(post))\n",
    "\n",
    "# Vectorizing text data\n",
    "count_vect = CountVectorizer()\n",
    "X_counts = count_vect.fit_transform(x)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X = tfidf_transformer.fit_transform(X_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7e92552",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-25T15:18:59.078766Z",
     "iopub.status.busy": "2021-10-25T15:18:59.077964Z",
     "iopub.status.idle": "2021-10-25T15:18:59.439776Z",
     "shell.execute_reply": "2021-10-25T15:18:59.439360Z"
    },
    "id": "-223yjJBgXqP",
    "papermill": {
     "duration": 0.373718,
     "end_time": "2021-10-25T15:18:59.439890",
     "exception": false,
     "start_time": "2021-10-25T15:18:59.066172",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(np.array(data['mental_disorder']))\n",
    "# y = to_categorical(y1)\n",
    "\n",
    "# 60-20-20 split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=321)\n",
    "X_test, X_valid, y_test, y_valid = train_test_split(X_test, y_test, test_size=0.5, random_state=321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbb5b12b",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-10-25T15:18:59.463534Z",
     "iopub.status.busy": "2021-10-25T15:18:59.462779Z",
     "iopub.status.idle": "2021-10-26T18:58:09.830998Z",
     "shell.execute_reply": "2021-10-26T18:58:09.831377Z"
    },
    "id": "D2ttwX1wge7y",
    "outputId": "4905873f-8936-459c-89e7-c31ed7b89100",
    "papermill": {
     "duration": 99550.383206,
     "end_time": "2021-10-26T18:58:09.831518",
     "exception": false,
     "start_time": "2021-10-25T15:18:59.448312",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################################################################################################\n",
      "\n",
      "With sampling type: 1\n",
      "\n",
      "For training set\n",
      "\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91      3472\n",
      "           1       0.91      0.89      0.90      3472\n",
      "           2       0.88      0.90      0.89      3472\n",
      "           3       0.91      0.94      0.93      3472\n",
      "           4       0.76      0.69      0.72      3472\n",
      "           5       0.94      0.91      0.92      3472\n",
      "           6       0.88      0.78      0.82      3472\n",
      "           7       0.73      0.73      0.73      3472\n",
      "           8       0.69      0.62      0.65      3472\n",
      "           9       0.88      0.91      0.89      3472\n",
      "          10       0.75      0.83      0.79      3472\n",
      "          11       0.91      0.88      0.90      3472\n",
      "          12       0.91      0.86      0.88      3472\n",
      "          13       0.77      0.81      0.79      3472\n",
      "          14       0.72      0.80      0.76      3472\n",
      "\n",
      "    accuracy                           0.83     52080\n",
      "   macro avg       0.83      0.83      0.83     52080\n",
      "weighted avg       0.83      0.83      0.83     52080\n",
      "\n",
      "Accuracy:  0.8329877112135177 \n",
      "\n",
      "\n",
      "\n",
      "For validation set\n",
      "\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.86      0.73      2817\n",
      "           1       0.58      0.79      0.67      1554\n",
      "           2       0.84      0.81      0.83      9266\n",
      "           3       0.62      0.86      0.72      1229\n",
      "           4       0.76      0.56      0.65     11636\n",
      "           5       0.62      0.78      0.69      1795\n",
      "           6       0.34      0.67      0.45      1175\n",
      "           7       0.42      0.55      0.47      4828\n",
      "           8       0.74      0.43      0.54     23524\n",
      "           9       0.46      0.83      0.59      1719\n",
      "          10       0.44      0.70      0.54      4596\n",
      "          11       0.56      0.76      0.64      1686\n",
      "          12       0.54      0.73      0.62      1749\n",
      "          13       0.50      0.66      0.57      4563\n",
      "          14       0.59      0.65      0.61     13163\n",
      "\n",
      "    accuracy                           0.61     85300\n",
      "   macro avg       0.58      0.71      0.62     85300\n",
      "weighted avg       0.65      0.61      0.61     85300\n",
      "\n",
      "Accuracy:  0.6146541617819461 \n",
      "\n",
      "\n",
      "\n",
      "For test set\n",
      "\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.85      0.72      2935\n",
      "           1       0.58      0.83      0.68      1521\n",
      "           2       0.84      0.80      0.82      9051\n",
      "           3       0.61      0.83      0.70      1175\n",
      "           4       0.77      0.57      0.66     11493\n",
      "           5       0.63      0.79      0.70      1781\n",
      "           6       0.33      0.65      0.44      1133\n",
      "           7       0.42      0.54      0.47      4921\n",
      "           8       0.73      0.43      0.54     23516\n",
      "           9       0.45      0.81      0.58      1695\n",
      "          10       0.45      0.71      0.55      4747\n",
      "          11       0.55      0.76      0.64      1769\n",
      "          12       0.53      0.72      0.61      1743\n",
      "          13       0.50      0.66      0.57      4524\n",
      "          14       0.58      0.64      0.61     13296\n",
      "\n",
      "    accuracy                           0.61     85300\n",
      "   macro avg       0.57      0.71      0.62     85300\n",
      "weighted avg       0.65      0.61      0.61     85300\n",
      "\n",
      "Accuracy:  0.6124150058616648 \n",
      "\n",
      "\n",
      "##############################################################################################################\n",
      "\n",
      "With sampling type: 3\n",
      "\n",
      "For training set\n",
      "\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89      3472\n",
      "           1       0.90      0.89      0.89      3472\n",
      "           2       0.89      0.89      0.89      3472\n",
      "           3       0.89      0.92      0.90      3472\n",
      "           4       0.73      0.69      0.71      3472\n",
      "           5       0.93      0.89      0.91      3472\n",
      "           6       0.78      0.76      0.77      3472\n",
      "           7       0.66      0.64      0.65      3472\n",
      "           8       0.61      0.52      0.56      3472\n",
      "           9       0.87      0.90      0.89      3472\n",
      "          10       0.72      0.81      0.76      3472\n",
      "          11       0.90      0.87      0.89      3472\n",
      "          12       0.87      0.83      0.85      3472\n",
      "          13       0.77      0.79      0.78      3472\n",
      "          14       0.65      0.74      0.69      3472\n",
      "\n",
      "    accuracy                           0.80     52080\n",
      "   macro avg       0.80      0.80      0.80     52080\n",
      "weighted avg       0.80      0.80      0.80     52080\n",
      "\n",
      "Accuracy:  0.8032834101382489 \n",
      "\n",
      "\n",
      "\n",
      "For validation set\n",
      "\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.85      0.70      2817\n",
      "           1       0.45      0.82      0.59      1554\n",
      "           2       0.92      0.68      0.78      9266\n",
      "           3       0.55      0.87      0.67      1229\n",
      "           4       0.77      0.39      0.52     11636\n",
      "           5       0.34      0.84      0.48      1795\n",
      "           6       0.20      0.66      0.31      1175\n",
      "           7       0.34      0.53      0.41      4828\n",
      "           8       0.77      0.23      0.35     23524\n",
      "           9       0.33      0.88      0.48      1719\n",
      "          10       0.45      0.59      0.51      4596\n",
      "          11       0.40      0.79      0.53      1686\n",
      "          12       0.46      0.75      0.57      1749\n",
      "          13       0.34      0.77      0.47      4563\n",
      "          14       0.55      0.59      0.57     13163\n",
      "\n",
      "    accuracy                           0.51     85300\n",
      "   macro avg       0.50      0.68      0.53     85300\n",
      "weighted avg       0.64      0.51      0.51     85300\n",
      "\n",
      "Accuracy:  0.5145603751465416 \n",
      "\n",
      "\n",
      "\n",
      "For test set\n",
      "\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.85      0.69      2935\n",
      "           1       0.45      0.85      0.59      1521\n",
      "           2       0.92      0.66      0.77      9051\n",
      "           3       0.53      0.85      0.65      1175\n",
      "           4       0.77      0.39      0.52     11493\n",
      "           5       0.33      0.85      0.48      1781\n",
      "           6       0.19      0.61      0.29      1133\n",
      "           7       0.34      0.53      0.41      4921\n",
      "           8       0.77      0.22      0.34     23516\n",
      "           9       0.32      0.85      0.46      1695\n",
      "          10       0.46      0.59      0.52      4747\n",
      "          11       0.40      0.78      0.53      1769\n",
      "          12       0.46      0.73      0.56      1743\n",
      "          13       0.34      0.76      0.47      4524\n",
      "          14       0.55      0.59      0.57     13296\n",
      "\n",
      "    accuracy                           0.51     85300\n",
      "   macro avg       0.49      0.67      0.52     85300\n",
      "weighted avg       0.63      0.51      0.50     85300\n",
      "\n",
      "Accuracy:  0.5102461899179367 \n",
      "\n",
      "\n",
      "##############################################################################################################\n",
      "\n",
      "With sampling type: 6\n",
      "\n",
      "For training set\n",
      "\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.86      0.87      8730\n",
      "           1       0.87      0.75      0.81      4501\n",
      "           2       0.89      0.90      0.89     27017\n",
      "           3       0.84      0.80      0.82      3470\n",
      "           4       0.76      0.77      0.76     33833\n",
      "           5       0.93      0.74      0.82      5194\n",
      "           6       0.81      0.51      0.63      3472\n",
      "           7       0.72      0.57      0.63     14364\n",
      "           8       0.65      0.79      0.71     69131\n",
      "           9       0.83      0.68      0.75      5114\n",
      "          10       0.69      0.61      0.65     13977\n",
      "          11       0.86      0.69      0.77      5114\n",
      "          12       0.89      0.68      0.77      5127\n",
      "          13       0.71      0.63      0.67     13633\n",
      "          14       0.70      0.65      0.67     38973\n",
      "\n",
      "    accuracy                           0.73    251650\n",
      "   macro avg       0.80      0.71      0.75    251650\n",
      "weighted avg       0.74      0.73      0.73    251650\n",
      "\n",
      "Accuracy:  0.7349135704351282 \n",
      "\n",
      "\n",
      "\n",
      "For validation set\n",
      "\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.80      0.82      2817\n",
      "           1       0.82      0.66      0.73      1554\n",
      "           2       0.86      0.86      0.86      9266\n",
      "           3       0.81      0.73      0.77      1229\n",
      "           4       0.70      0.73      0.71     11636\n",
      "           5       0.91      0.68      0.78      1795\n",
      "           6       0.73      0.45      0.56      1175\n",
      "           7       0.64      0.48      0.55      4828\n",
      "           8       0.59      0.74      0.66     23524\n",
      "           9       0.76      0.60      0.67      1719\n",
      "          10       0.61      0.52      0.56      4596\n",
      "          11       0.80      0.60      0.69      1686\n",
      "          12       0.85      0.62      0.72      1749\n",
      "          13       0.63      0.54      0.58      4563\n",
      "          14       0.64      0.59      0.61     13163\n",
      "\n",
      "    accuracy                           0.68     85300\n",
      "   macro avg       0.75      0.64      0.69     85300\n",
      "weighted avg       0.69      0.68      0.68     85300\n",
      "\n",
      "Accuracy:  0.6779132473622509 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For test set\n",
      "\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.78      0.81      2935\n",
      "           1       0.80      0.68      0.73      1521\n",
      "           2       0.86      0.86      0.86      9051\n",
      "           3       0.81      0.71      0.76      1175\n",
      "           4       0.71      0.73      0.72     11493\n",
      "           5       0.91      0.70      0.79      1781\n",
      "           6       0.73      0.41      0.53      1133\n",
      "           7       0.62      0.48      0.55      4921\n",
      "           8       0.59      0.74      0.65     23516\n",
      "           9       0.75      0.57      0.65      1695\n",
      "          10       0.63      0.53      0.58      4747\n",
      "          11       0.82      0.60      0.69      1769\n",
      "          12       0.83      0.60      0.70      1743\n",
      "          13       0.63      0.55      0.59      4524\n",
      "          14       0.63      0.58      0.61     13296\n",
      "\n",
      "    accuracy                           0.68     85300\n",
      "   macro avg       0.74      0.64      0.68     85300\n",
      "weighted avg       0.68      0.68      0.67     85300\n",
      "\n",
      "Accuracy:  0.6752872215709261 \n",
      "\n",
      "\n",
      "##############################################################################################################\n",
      "\n",
      "Without any undersampling/oversampling\n",
      "\n",
      "For training set\n",
      "\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97     70291\n",
      "           1       0.97      0.98      0.98     70291\n",
      "           2       0.92      0.91      0.92     70291\n",
      "           3       0.97      0.99      0.98     70291\n",
      "           4       0.83      0.74      0.78     70291\n",
      "           5       0.92      0.97      0.94     70291\n",
      "           6       0.95      0.96      0.95     70291\n",
      "           7       0.83      0.81      0.82     70291\n",
      "           8       0.67      0.56      0.61     70291\n",
      "           9       0.94      0.97      0.96     70291\n",
      "          10       0.81      0.85      0.83     70291\n",
      "          11       0.96      0.97      0.96     70291\n",
      "          12       0.96      0.96      0.96     70291\n",
      "          13       0.85      0.87      0.86     70291\n",
      "          14       0.70      0.76      0.73     70291\n",
      "\n",
      "    accuracy                           0.88   1054365\n",
      "   macro avg       0.88      0.88      0.88   1054365\n",
      "weighted avg       0.88      0.88      0.88   1054365\n",
      "\n",
      "Accuracy:  0.8846367244739725 \n",
      "\n",
      "\n",
      "\n",
      "For validation set\n",
      "\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.81      2817\n",
      "           1       0.67      0.78      0.72      1554\n",
      "           2       0.85      0.85      0.85      9266\n",
      "           3       0.72      0.81      0.77      1229\n",
      "           4       0.75      0.63      0.68     11636\n",
      "           5       0.61      0.80      0.69      1795\n",
      "           6       0.40      0.60      0.48      1175\n",
      "           7       0.46      0.58      0.51      4828\n",
      "           8       0.71      0.51      0.59     23524\n",
      "           9       0.58      0.79      0.67      1719\n",
      "          10       0.47      0.69      0.56      4596\n",
      "          11       0.61      0.75      0.67      1686\n",
      "          12       0.63      0.73      0.67      1749\n",
      "          13       0.54      0.66      0.59      4563\n",
      "          14       0.58      0.63      0.60     13163\n",
      "\n",
      "    accuracy                           0.64     85300\n",
      "   macro avg       0.62      0.71      0.66     85300\n",
      "weighted avg       0.66      0.64      0.65     85300\n",
      "\n",
      "Accuracy:  0.6449355216881595 \n",
      "\n",
      "\n",
      "\n",
      "For test set\n",
      "\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.83      0.80      2935\n",
      "           1       0.66      0.80      0.73      1521\n",
      "           2       0.84      0.85      0.85      9051\n",
      "           3       0.71      0.80      0.75      1175\n",
      "           4       0.75      0.63      0.69     11493\n",
      "           5       0.62      0.82      0.70      1781\n",
      "           6       0.41      0.60      0.49      1133\n",
      "           7       0.46      0.58      0.51      4921\n",
      "           8       0.71      0.51      0.59     23516\n",
      "           9       0.57      0.76      0.65      1695\n",
      "          10       0.48      0.69      0.57      4747\n",
      "          11       0.61      0.74      0.67      1769\n",
      "          12       0.63      0.71      0.67      1743\n",
      "          13       0.54      0.66      0.59      4524\n",
      "          14       0.58      0.63      0.60     13296\n",
      "\n",
      "    accuracy                           0.64     85300\n",
      "   macro avg       0.62      0.71      0.66     85300\n",
      "weighted avg       0.66      0.64      0.64     85300\n",
      "\n",
      "Accuracy:  0.6438804220398593 \n",
      "\n",
      "\n",
      "##############################################################################################################\n",
      "\n",
      "With sampling type: 0\n",
      "\n",
      "For training set\n",
      "\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96     70291\n",
      "           1       0.96      0.98      0.97     70291\n",
      "           2       0.92      0.91      0.92     70291\n",
      "           3       0.97      0.99      0.98     70291\n",
      "           4       0.80      0.71      0.75     70291\n",
      "           5       0.96      0.98      0.97     70291\n",
      "           6       0.93      0.96      0.95     70291\n",
      "           7       0.81      0.77      0.79     70291\n",
      "           8       0.65      0.53      0.59     70291\n",
      "           9       0.93      0.97      0.95     70291\n",
      "          10       0.79      0.86      0.82     70291\n",
      "          11       0.94      0.97      0.95     70291\n",
      "          12       0.94      0.96      0.95     70291\n",
      "          13       0.82      0.84      0.83     70291\n",
      "          14       0.72      0.74      0.73     70291\n",
      "\n",
      "    accuracy                           0.88   1054365\n",
      "   macro avg       0.87      0.88      0.87   1054365\n",
      "weighted avg       0.87      0.88      0.87   1054365\n",
      "\n",
      "Accuracy:  0.8760618950742864 \n",
      "\n",
      "\n",
      "\n",
      "For validation set\n",
      "\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.86      0.79      2817\n",
      "           1       0.64      0.79      0.70      1554\n",
      "           2       0.86      0.85      0.85      9266\n",
      "           3       0.69      0.83      0.75      1229\n",
      "           4       0.75      0.62      0.68     11636\n",
      "           5       0.68      0.80      0.73      1795\n",
      "           6       0.39      0.63      0.48      1175\n",
      "           7       0.47      0.59      0.52      4828\n",
      "           8       0.74      0.48      0.58     23524\n",
      "           9       0.56      0.81      0.66      1719\n",
      "          10       0.46      0.71      0.56      4596\n",
      "          11       0.57      0.77      0.66      1686\n",
      "          12       0.58      0.76      0.66      1749\n",
      "          13       0.52      0.68      0.59      4563\n",
      "          14       0.61      0.65      0.63     13163\n",
      "\n",
      "    accuracy                           0.65     85300\n",
      "   macro avg       0.62      0.72      0.66     85300\n",
      "weighted avg       0.67      0.65      0.65     85300\n",
      "\n",
      "Accuracy:  0.6460375146541618 \n",
      "\n",
      "\n",
      "\n",
      "For test set\n",
      "\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.85      0.79      2935\n",
      "           1       0.63      0.82      0.71      1521\n",
      "           2       0.86      0.85      0.85      9051\n",
      "           3       0.69      0.81      0.75      1175\n",
      "           4       0.75      0.62      0.68     11493\n",
      "           5       0.68      0.81      0.74      1781\n",
      "           6       0.39      0.63      0.48      1133\n",
      "           7       0.47      0.59      0.52      4921\n",
      "           8       0.73      0.48      0.58     23516\n",
      "           9       0.54      0.77      0.63      1695\n",
      "          10       0.46      0.71      0.56      4747\n",
      "          11       0.57      0.76      0.65      1769\n",
      "          12       0.57      0.73      0.64      1743\n",
      "          13       0.52      0.69      0.59      4524\n",
      "          14       0.61      0.65      0.63     13296\n",
      "\n",
      "    accuracy                           0.64     85300\n",
      "   macro avg       0.61      0.72      0.65     85300\n",
      "weighted avg       0.67      0.64      0.64     85300\n",
      "\n",
      "Accuracy:  0.6438569753810082 \n",
      "\n",
      "\n",
      "##############################################################################################################\n",
      "\n",
      "With sampling type: 2\n",
      "\n",
      "For training set\n",
      "\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97     70291\n",
      "           1       0.97      0.98      0.97     70291\n",
      "           2       0.92      0.91      0.92     70291\n",
      "           3       0.97      0.99      0.98     70291\n",
      "           4       0.82      0.74      0.78     70291\n",
      "           5       0.92      0.97      0.94     70291\n",
      "           6       0.95      0.96      0.95     70291\n",
      "           7       0.83      0.81      0.82     70291\n",
      "           8       0.67      0.56      0.61     70291\n",
      "           9       0.94      0.97      0.96     70291\n",
      "          10       0.81      0.85      0.83     70291\n",
      "          11       0.96      0.97      0.96     70291\n",
      "          12       0.96      0.96      0.96     70291\n",
      "          13       0.85      0.87      0.86     70291\n",
      "          14       0.70      0.76      0.73     70291\n",
      "\n",
      "    accuracy                           0.88   1054365\n",
      "   macro avg       0.88      0.88      0.88   1054365\n",
      "weighted avg       0.88      0.88      0.88   1054365\n",
      "\n",
      "Accuracy:  0.8844166868209775 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For validation set\n",
      "\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.81      2817\n",
      "           1       0.67      0.78      0.72      1554\n",
      "           2       0.84      0.85      0.85      9266\n",
      "           3       0.72      0.81      0.76      1229\n",
      "           4       0.74      0.62      0.68     11636\n",
      "           5       0.62      0.80      0.69      1795\n",
      "           6       0.41      0.60      0.49      1175\n",
      "           7       0.46      0.58      0.51      4828\n",
      "           8       0.71      0.51      0.59     23524\n",
      "           9       0.58      0.78      0.67      1719\n",
      "          10       0.47      0.69      0.56      4596\n",
      "          11       0.61      0.75      0.67      1686\n",
      "          12       0.63      0.73      0.67      1749\n",
      "          13       0.54      0.66      0.59      4563\n",
      "          14       0.58      0.63      0.60     13163\n",
      "\n",
      "    accuracy                           0.64     85300\n",
      "   macro avg       0.62      0.71      0.66     85300\n",
      "weighted avg       0.66      0.64      0.64     85300\n",
      "\n",
      "Accuracy:  0.6434701055099649 \n",
      "\n",
      "\n",
      "\n",
      "For test set\n",
      "\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.83      0.80      2935\n",
      "           1       0.67      0.81      0.73      1521\n",
      "           2       0.84      0.85      0.85      9051\n",
      "           3       0.72      0.79      0.75      1175\n",
      "           4       0.75      0.63      0.69     11493\n",
      "           5       0.62      0.82      0.71      1781\n",
      "           6       0.41      0.60      0.49      1133\n",
      "           7       0.46      0.58      0.51      4921\n",
      "           8       0.71      0.51      0.59     23516\n",
      "           9       0.57      0.76      0.65      1695\n",
      "          10       0.48      0.69      0.57      4747\n",
      "          11       0.61      0.74      0.67      1769\n",
      "          12       0.62      0.71      0.66      1743\n",
      "          13       0.54      0.66      0.59      4524\n",
      "          14       0.58      0.63      0.60     13296\n",
      "\n",
      "    accuracy                           0.64     85300\n",
      "   macro avg       0.62      0.71      0.66     85300\n",
      "weighted avg       0.66      0.64      0.64     85300\n",
      "\n",
      "Accuracy:  0.6440328253223916 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "X_tr, y_tr = X_train, y_train\n",
    "\n",
    "for _type in [1, 3, 6, -1, 0, 2]:\n",
    "    print('#'*110)\n",
    "    print()\n",
    "    if _type == -1:\n",
    "        print('Without any undersampling/oversampling')\n",
    "    else:\n",
    "        print(f'With sampling type: {_type}')\n",
    "    model = BaggingClassifier(base_estimator=LogisticRegression(max_iter=10000))\n",
    "    X_train, y_train = balance_data(X_tr, y_tr, _type)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    print()\n",
    "    print(\"For training set\")\n",
    "    print()\n",
    "    get_metrics(y_train, y_train_pred)\n",
    "\n",
    "    y_valid_pred = model.predict(X_valid)\n",
    "    print()\n",
    "    print(\"For validation set\")\n",
    "    print()\n",
    "    get_metrics(y_valid, y_valid_pred)\n",
    "\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    print()\n",
    "    print(\"For test set\")\n",
    "    print()\n",
    "    get_metrics(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fcd878",
   "metadata": {
    "id": "XxJyapqrhB9M",
    "papermill": {
     "duration": 0.014739,
     "end_time": "2021-10-26T18:58:09.860142",
     "exception": false,
     "start_time": "2021-10-26T18:58:09.845403",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Bagging One vs rest.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 99634.586201,
   "end_time": "2021-10-26T18:58:13.241378",
   "environment_variables": {},
   "exception": null,
   "input_path": "/home2/tgv2002/mrinal_IRE/IRE-Project-Team-7/Bagging_One_vs_rest.ipynb",
   "output_path": "/home2/tgv2002/mrinal_IRE/outputs/Baggin_ovr_out.ipynb",
   "parameters": {},
   "start_time": "2021-10-25T15:17:38.655177",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
