{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bagging One vs rest.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1N9bc-Cf_m7"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import re\n",
        "import nltk\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from nltk.corpus import stopwords\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models.keyedvectors import KeyedVectors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTEZ3LAngLCv"
      },
      "source": [
        "def get_metrics(y_true, y_pred):\n",
        "    result1 = classification_report(y_true, y_pred)\n",
        "    print('Classification Report: ', result1)\n",
        "    result2 = accuracy_score(y_true, y_pred)\n",
        "    print('Accuracy: ', result2, \"\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIvEjix7gQRj",
        "outputId": "1fb37836-6650-4b05-a81c-b40f99a853fe"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CX9H85mEgRn8"
      },
      "source": [
        " stop_words = set(stopwords.words('english'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LA6HfIqfgTNQ"
      },
      "source": [
        "def clean_post(post):\n",
        "  post = post.lower()\n",
        "  post = re.sub(r\"\\n\", \" \", post)\n",
        "  post = re.sub(\"[\\<\\[].*?[\\>\\]]\", \" \", post)\n",
        "  post = re.sub(r\"[^a-z ]\", \" \", post)\n",
        "  post = re.sub(r\"\\b\\w{1,3}\\b\", \" \", post)\n",
        "  return \" \".join([x for x in post.split() if x not in stop_words])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71AR95q8gUqZ"
      },
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler, TomekLinks, NearMiss, ClusterCentroids\n",
        "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
        "from imblearn.combine import SMOTETomek\n",
        "\n",
        "def balance_data(x, y, _type):\n",
        "  if _type == 0:\n",
        "    ros = RandomOverSampler(random_state=42)\n",
        "    return ros.fit_resample(x, y)\n",
        "  elif _type == 1:\n",
        "    rus = RandomUnderSampler(random_state=42, replacement=True)\n",
        "    return rus.fit_resample(x, y)\n",
        "  elif _type == 2:\n",
        "    smote = SMOTE()\n",
        "    return smote.fit_resample(x, y)\n",
        "  elif _type == 3:\n",
        "    nm = NearMiss()\n",
        "    return nm.fit_resample(x, y)\n",
        "  elif _type == 4:\n",
        "    smt = SMOTETomek(ratio='auto')\n",
        "    return smt.fit_resample(x, y)\n",
        "  elif _type == 5:\n",
        "    cc = ClusterCentroids()\n",
        "    return cc.fit_resample(x, y)\n",
        "  elif _type == 6:\n",
        "    tl = TomekLinks()\n",
        "    return tl.fit_resample(x, y)\n",
        "  # default\n",
        "  smote = SMOTE()\n",
        "  return smote.fit_resample(x, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFXVnznpgWKc",
        "outputId": "c18dc80e-3167-4c56-f9b4-185c3a84697e"
      },
      "source": [
        "data = pd.read_csv('../../reddit_mental_health_dataset/reddit_dataset.csv')\n",
        "data = shuffle(data)\n",
        "\n",
        "# Class split stats\n",
        "print(data.groupby(['mental_disorder'])[['mental_disorder']].describe())\n",
        "x = data['post'].apply(lambda post: clean_post(post))\n",
        "\n",
        "# Vectorizing text data\n",
        "count_vect = CountVectorizer()\n",
        "X_counts = count_vect.fit_transform(x)\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "X = tfidf_transformer.fit_transform(X_counts)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                mental_disorder                              \n",
            "                          count unique            top    freq\n",
            "mental_disorder                                              \n",
            "EDAnonymous               14577      1    EDAnonymous   14577\n",
            "addiction                  7641      1      addiction    7641\n",
            "adhd                      45631      1           adhd   45631\n",
            "alcoholism                 5911      1     alcoholism    5911\n",
            "anxiety                   57671      1        anxiety   57671\n",
            "autism                     8869      1         autism    8869\n",
            "bipolarreddit              5780      1  bipolarreddit    5780\n",
            "bpd                       24294      1            bpd   24294\n",
            "depression               117331      1     depression  117331\n",
            "healthanxiety              8648      1  healthanxiety    8648\n",
            "lonely                    23635      1         lonely   23635\n",
            "ptsd                       8643      1           ptsd    8643\n",
            "schizophrenia              8712      1  schizophrenia    8712\n",
            "socialanxiety             22996      1  socialanxiety   22996\n",
            "suicidewatch              66161      1   suicidewatch   66161\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-223yjJBgXqP"
      },
      "source": [
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(np.array(data['mental_disorder']))\n",
        "# y = to_categorical(y1)\n",
        "\n",
        "# 60-20-20 split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=321)\n",
        "X_test, X_valid, y_test, y_valid = train_test_split(X_test, y_test, test_size=0.5, random_state=321)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2ttwX1wge7y",
        "outputId": "4905873f-8936-459c-89e7-c31ed7b89100"
      },
      "source": [
        "import gc\n",
        "\n",
        "X_tr, y_tr = X_train, y_train\n",
        "\n",
        "for _type in [1, 3, 6, -1, 0, 2]:\n",
        "  print('#'*110)\n",
        "  print()\n",
        "  if _type == -1:\n",
        "    print('Without any undersampling/oversampling')\n",
        "  else:\n",
        "    print(f'With sampling type: {_type}')\n",
        "  model = BaggingClassifier(base_estimator=LogisticRegression(max_iter=10000))\n",
        "  X_train, y_train = balance_data(X_tr, y_tr, _type)\n",
        "  model.fit(X_train, y_train)\n",
        "\n",
        "  y_train_pred = model.predict(X_train)\n",
        "  print()\n",
        "  print(\"For training set\")\n",
        "  print()\n",
        "  get_metrics(y_train, y_train_pred)\n",
        "\n",
        "  y_valid_pred = model.predict(X_valid)\n",
        "  print()\n",
        "  print(\"For validation set\")\n",
        "  print()\n",
        "  get_metrics(y_valid, y_valid_pred)\n",
        "\n",
        "  y_test_pred = model.predict(X_test)\n",
        "  print()\n",
        "  print(\"For test set\")\n",
        "  print()\n",
        "  get_metrics(y_test, y_test_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "##############################################################################################################\n",
            "\n",
            "With sampling type: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "For training set\n",
            "\n",
            "Classification Report:                precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.94      0.91      3444\n",
            "           1       0.91      0.91      0.91      3444\n",
            "           2       0.90      0.89      0.89      3444\n",
            "           3       0.91      0.93      0.92      3444\n",
            "           4       0.76      0.70      0.73      3444\n",
            "           5       0.94      0.91      0.93      3444\n",
            "           6       0.87      0.78      0.82      3444\n",
            "           7       0.73      0.72      0.73      3444\n",
            "           8       0.67      0.61      0.64      3444\n",
            "           9       0.89      0.92      0.90      3444\n",
            "          10       0.75      0.85      0.80      3444\n",
            "          11       0.91      0.89      0.90      3444\n",
            "          12       0.91      0.86      0.89      3444\n",
            "          13       0.78      0.82      0.80      3444\n",
            "          14       0.70      0.78      0.74      3444\n",
            "\n",
            "    accuracy                           0.83     51660\n",
            "   macro avg       0.84      0.83      0.83     51660\n",
            "weighted avg       0.84      0.83      0.83     51660\n",
            "\n",
            "Accuracy:  0.8344947735191638 \n",
            "\n",
            "\n",
            "\n",
            "For validation set\n",
            "\n",
            "Classification Report:                precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.87      0.73      2924\n",
            "           1       0.61      0.81      0.69      1529\n",
            "           2       0.85      0.81      0.83      9091\n",
            "           3       0.63      0.86      0.73      1202\n",
            "           4       0.75      0.56      0.64     11581\n",
            "           5       0.64      0.80      0.71      1748\n",
            "           6       0.34      0.63      0.44      1144\n",
            "           7       0.42      0.55      0.48      4886\n",
            "           8       0.73      0.44      0.55     23427\n",
            "           9       0.45      0.82      0.58      1761\n",
            "          10       0.45      0.70      0.55      4806\n",
            "          11       0.55      0.77      0.64      1718\n",
            "          12       0.55      0.71      0.62      1712\n",
            "          13       0.51      0.66      0.58      4690\n",
            "          14       0.58      0.63      0.60     13081\n",
            "\n",
            "    accuracy                           0.61     85300\n",
            "   macro avg       0.58      0.71      0.62     85300\n",
            "weighted avg       0.65      0.61      0.61     85300\n",
            "\n",
            "Accuracy:  0.6143962485345839 \n",
            "\n",
            "\n",
            "\n",
            "For test set\n",
            "\n",
            "Classification Report:                precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.86      0.73      3041\n",
            "           1       0.61      0.79      0.69      1578\n",
            "           2       0.85      0.81      0.83      9234\n",
            "           3       0.61      0.87      0.72      1222\n",
            "           4       0.76      0.57      0.65     11514\n",
            "           5       0.66      0.78      0.71      1785\n",
            "           6       0.37      0.67      0.48      1192\n",
            "           7       0.42      0.56      0.48      4704\n",
            "           8       0.72      0.43      0.54     23396\n",
            "           9       0.46      0.82      0.59      1755\n",
            "          10       0.45      0.71      0.55      4742\n",
            "          11       0.55      0.75      0.63      1681\n",
            "          12       0.55      0.72      0.62      1738\n",
            "          13       0.51      0.66      0.57      4527\n",
            "          14       0.58      0.63      0.60     13191\n",
            "\n",
            "    accuracy                           0.62     85300\n",
            "   macro avg       0.58      0.71      0.63     85300\n",
            "weighted avg       0.65      0.62      0.61     85300\n",
            "\n",
            "Accuracy:  0.6154396248534584 \n",
            "\n",
            "\n",
            "##############################################################################################################\n",
            "\n",
            "With sampling type: 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "For training set\n",
            "\n",
            "Classification Report:                precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.91      0.89      3444\n",
            "           1       0.89      0.89      0.89      3444\n",
            "           2       0.88      0.89      0.89      3444\n",
            "           3       0.89      0.92      0.90      3444\n",
            "           4       0.74      0.71      0.72      3444\n",
            "           5       0.93      0.90      0.91      3444\n",
            "           6       0.79      0.75      0.77      3444\n",
            "           7       0.66      0.63      0.65      3444\n",
            "           8       0.59      0.50      0.54      3444\n",
            "           9       0.87      0.90      0.89      3444\n",
            "          10       0.72      0.81      0.76      3444\n",
            "          11       0.90      0.86      0.88      3444\n",
            "          12       0.87      0.84      0.85      3444\n",
            "          13       0.77      0.79      0.78      3444\n",
            "          14       0.65      0.73      0.69      3444\n",
            "\n",
            "    accuracy                           0.80     51660\n",
            "   macro avg       0.80      0.80      0.80     51660\n",
            "weighted avg       0.80      0.80      0.80     51660\n",
            "\n",
            "Accuracy:  0.8019357336430507 \n",
            "\n",
            "\n",
            "\n",
            "For validation set\n",
            "\n",
            "Classification Report:                precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.87      0.72      2924\n",
            "           1       0.48      0.82      0.60      1529\n",
            "           2       0.92      0.69      0.79      9091\n",
            "           3       0.52      0.88      0.65      1202\n",
            "           4       0.76      0.39      0.51     11581\n",
            "           5       0.35      0.85      0.50      1748\n",
            "           6       0.20      0.60      0.30      1144\n",
            "           7       0.32      0.54      0.40      4886\n",
            "           8       0.76      0.23      0.35     23427\n",
            "           9       0.33      0.86      0.47      1761\n",
            "          10       0.48      0.57      0.52      4806\n",
            "          11       0.42      0.80      0.55      1718\n",
            "          12       0.45      0.72      0.55      1712\n",
            "          13       0.34      0.76      0.47      4690\n",
            "          14       0.55      0.59      0.57     13081\n",
            "\n",
            "    accuracy                           0.52     85300\n",
            "   macro avg       0.50      0.68      0.53     85300\n",
            "weighted avg       0.63      0.52      0.51     85300\n",
            "\n",
            "Accuracy:  0.5159554513481829 \n",
            "\n",
            "\n",
            "\n",
            "For test set\n",
            "\n",
            "Classification Report:                precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.85      0.70      3041\n",
            "           1       0.48      0.82      0.61      1578\n",
            "           2       0.92      0.69      0.78      9234\n",
            "           3       0.51      0.88      0.64      1222\n",
            "           4       0.77      0.40      0.53     11514\n",
            "           5       0.35      0.85      0.50      1785\n",
            "           6       0.22      0.64      0.33      1192\n",
            "           7       0.32      0.56      0.41      4704\n",
            "           8       0.76      0.23      0.36     23396\n",
            "           9       0.33      0.87      0.48      1755\n",
            "          10       0.48      0.57      0.52      4742\n",
            "          11       0.40      0.77      0.53      1681\n",
            "          12       0.46      0.73      0.56      1738\n",
            "          13       0.34      0.76      0.47      4527\n",
            "          14       0.56      0.59      0.57     13191\n",
            "\n",
            "    accuracy                           0.52     85300\n",
            "   macro avg       0.50      0.68      0.53     85300\n",
            "weighted avg       0.63      0.52      0.51     85300\n",
            "\n",
            "Accuracy:  0.519073856975381 \n",
            "\n",
            "\n",
            "##############################################################################################################\n",
            "\n",
            "With sampling type: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxJyapqrhB9M"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}