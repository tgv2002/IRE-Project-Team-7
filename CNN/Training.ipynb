{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d09f5c37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-05T07:05:20.075386Z",
     "iopub.status.busy": "2021-11-05T07:05:20.074884Z",
     "iopub.status.idle": "2021-11-05T07:05:20.077732Z",
     "shell.execute_reply": "2021-11-05T07:05:20.077232Z"
    },
    "papermill": {
     "duration": 0.013586,
     "end_time": "2021-11-05T07:05:20.077842",
     "exception": false,
     "start_time": "2021-11-05T07:05:20.064256",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Required installations\n",
    "# !pip cache purge\n",
    "# !python3 -m pip install -U scikit-learn scipy\n",
    "# !pip install nltk\n",
    "# !pip install keras\n",
    "# !pip install gensim\n",
    "# !pip install matplotlib\n",
    "# !pip install pandas\n",
    "# !pip install scikit-learn\n",
    "# !pip install nltk\n",
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "equal-taylor",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-05T07:05:20.105290Z",
     "iopub.status.busy": "2021-11-05T07:05:20.104760Z",
     "iopub.status.idle": "2021-11-05T07:05:39.511872Z",
     "shell.execute_reply": "2021-11-05T07:05:39.511429Z"
    },
    "papermill": {
     "duration": 19.425545,
     "end_time": "2021-11-05T07:05:39.511982",
     "exception": false,
     "start_time": "2021-11-05T07:05:20.086437",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Required imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from nltk.corpus import stopwords\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dense, Input, GlobalMaxPooling1D, GlobalAveragePooling2D\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Embedding, Conv2D, MaxPooling2D, Dropout,concatenate\n",
    "from keras.layers.core import Reshape, Flatten\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import SGD, RMSprop, Adagrad, Adadelta, Adam, Adamax, Nadam\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models.keyedvectors import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "artificial-phenomenon",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-05T07:05:39.532859Z",
     "iopub.status.busy": "2021-11-05T07:05:39.532349Z",
     "iopub.status.idle": "2021-11-05T07:05:39.534043Z",
     "shell.execute_reply": "2021-11-05T07:05:39.534416Z"
    },
    "papermill": {
     "duration": 0.013887,
     "end_time": "2021-11-05T07:05:39.534527",
     "exception": false,
     "start_time": "2021-11-05T07:05:39.520640",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cleaning data\n",
    "def clean_post(post):\n",
    "    post = post.lower()\n",
    "    post = re.sub(r\"\\n\", \" \", post)\n",
    "    post = re.sub(\"[\\<\\[].*?[\\>\\]]\", \" \", post)\n",
    "    post = re.sub(r\"[^a-z ]\", \" \", post)\n",
    "    post = re.sub(r\"\\b\\w{1,3}\\b\", \" \", post)\n",
    "    return \" \".join([x for x in post.split() if x not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e15568e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-05T07:05:39.557123Z",
     "iopub.status.busy": "2021-11-05T07:05:39.556644Z",
     "iopub.status.idle": "2021-11-05T07:05:39.558203Z",
     "shell.execute_reply": "2021-11-05T07:05:39.558564Z"
    },
    "papermill": {
     "duration": 0.015535,
     "end_time": "2021-11-05T07:05:39.558672",
     "exception": false,
     "start_time": "2021-11-05T07:05:39.543137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Different techniques for tackling class imbalance\n",
    "from imblearn.under_sampling import RandomUnderSampler, TomekLinks, NearMiss, ClusterCentroids\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "\n",
    "def balance_data(x, y, _type):\n",
    "    if _type == 0:\n",
    "        ros = RandomOverSampler(random_state=42)\n",
    "        return ros.fit_resample(x, y)\n",
    "    elif _type == 1:\n",
    "        rus = RandomUnderSampler(random_state=42, replacement=True)\n",
    "        return rus.fit_resample(x, y)\n",
    "    elif _type == 2:\n",
    "        smote = SMOTE()\n",
    "        return smote.fit_resample(x, y)\n",
    "    elif _type == 3:\n",
    "        nm = NearMiss()\n",
    "        return nm.fit_resample(x, y)\n",
    "    elif _type == 5:\n",
    "        cc = ClusterCentroids()\n",
    "        return cc.fit_resample(x, y)\n",
    "    elif _type == 6:\n",
    "        tl = TomekLinks()\n",
    "        return tl.fit_resample(x, y)\n",
    "    return x, y\n",
    "    # Another technique is penalizing the algo with class_weight=balanced, using stratified cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daily-office",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-05T07:05:39.579916Z",
     "iopub.status.busy": "2021-11-05T07:05:39.579430Z",
     "iopub.status.idle": "2021-11-05T07:06:14.833707Z",
     "shell.execute_reply": "2021-11-05T07:06:14.834080Z"
    },
    "papermill": {
     "duration": 35.267071,
     "end_time": "2021-11-05T07:06:14.834223",
     "exception": false,
     "start_time": "2021-11-05T07:05:39.567152",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                mental_disorder                             \n",
      "                          count unique            top   freq\n",
      "mental_disorder                                             \n",
      "EDAnonymous               12339      1    EDAnonymous  12339\n",
      "addiction                  6515      1      addiction   6515\n",
      "adhd                      38786      1           adhd  38786\n",
      "alcoholism                 5026      1     alcoholism   5026\n",
      "anxiety                   48971      1        anxiety  48971\n",
      "autism                     7583      1         autism   7583\n",
      "bipolarreddit              4929      1  bipolarreddit   4929\n",
      "bpd                       20606      1            bpd  20606\n",
      "depression                99809      1     depression  99809\n",
      "healthanxiety              7373      1  healthanxiety   7373\n",
      "lonely                    20103      1         lonely  20103\n",
      "ptsd                       7336      1           ptsd   7336\n",
      "schizophrenia              7351      1  schizophrenia   7351\n",
      "socialanxiety             19416      1  socialanxiety  19416\n",
      "suicidewatch              56357      1   suicidewatch  56357\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data = pd.read_csv('../split_data/train_and_valid.csv')\n",
    "data = shuffle(data)\n",
    "\n",
    "# Class split stats\n",
    "print(data.groupby(['mental_disorder'])[['mental_disorder']].describe())\n",
    "X = data['post'].apply(lambda post: clean_post(post))\n",
    "label_encoder = LabelEncoder()\n",
    "y1 = label_encoder.fit_transform(np.array(data['mental_disorder']))\n",
    "y = to_categorical(y1)\n",
    "\n",
    "# 70-15-15 split (test data is unseen)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.176, random_state=321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "expired-bikini",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-05T07:06:14.902195Z",
     "iopub.status.busy": "2021-11-05T07:06:14.881950Z",
     "iopub.status.idle": "2021-11-05T07:06:28.253714Z",
     "shell.execute_reply": "2021-11-05T07:06:28.254103Z"
    },
    "papermill": {
     "duration": 13.408462,
     "end_time": "2021-11-05T07:06:28.254264",
     "exception": false,
     "start_time": "2021-11-05T07:06:14.845802",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens found: 110301\n"
     ]
    }
   ],
   "source": [
    "# Using keras tokenizer on text for pre-processing\n",
    "MAX_WORDS_LIMIT = 30000\n",
    "tokenizer = Tokenizer(num_words=MAX_WORDS_LIMIT, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\\'', lower=True)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "with open('../models/tokenizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tokenizer, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "word_index = tokenizer.word_index\n",
    "print(f'Unique tokens found: {len(word_index)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "offshore-discipline",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-05T07:06:28.315880Z",
     "iopub.status.busy": "2021-11-05T07:06:28.295422Z",
     "iopub.status.idle": "2021-11-05T07:06:42.841646Z",
     "shell.execute_reply": "2021-11-05T07:06:42.842100Z"
    },
    "papermill": {
     "duration": 14.578105,
     "end_time": "2021-11-05T07:06:42.842241",
     "exception": false,
     "start_time": "2021-11-05T07:06:28.264136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X train tensor: (298700, 200), X validation tensor: (63800, 200)\n",
      "Shape of y train tensor: (298700, 15), y validation tensor: (63800, 15)\n"
     ]
    }
   ],
   "source": [
    "# Convert  texts to sequence of integers\n",
    "sequences_train = tokenizer.texts_to_sequences(X_train)\n",
    "sequences_valid = tokenizer.texts_to_sequences(X_valid)\n",
    "\n",
    "# Limit size of train/validation/test sequences to 200 and pad the sequence\n",
    "X_train = pad_sequences(sequences_train, maxlen=200)\n",
    "X_valid = pad_sequences(sequences_valid, maxlen=X_train.shape[1])\n",
    "print(f'Shape of X train tensor: {X_train.shape}, X validation tensor: {X_valid.shape}')\n",
    "\n",
    "# Convert target to array\n",
    "y_train, y_valid = np.asarray(y_train), np.asarray(y_valid)\n",
    "print(f'Shape of y train tensor: {y_train.shape}, y validation tensor: {y_valid.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "respected-belize",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-05T07:06:42.867680Z",
     "iopub.status.busy": "2021-11-05T07:06:42.867103Z",
     "iopub.status.idle": "2021-11-05T07:07:14.336842Z",
     "shell.execute_reply": "2021-11-05T07:07:14.337254Z"
    },
    "papermill": {
     "duration": 31.4845,
     "end_time": "2021-11-05T07:07:14.337393",
     "exception": false,
     "start_time": "2021-11-05T07:06:42.852893",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating word embeddings via pre-trained word2vec model\n",
    "WORD_EMBEDDING_DIM = 300\n",
    "word_vectors = KeyedVectors.load_word2vec_format('../reddit_mental_health_dataset/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "embeddings_matrix = np.zeros((MAX_WORDS_LIMIT, WORD_EMBEDDING_DIM))\n",
    "\n",
    "# Computing embeddings matrix and embedding layer\n",
    "for word, i in word_index.items():\n",
    "    if i >= MAX_WORDS_LIMIT:\n",
    "        break\n",
    "    try:\n",
    "        embeddings_matrix[i] = word_vectors[word]\n",
    "    except:\n",
    "        embeddings_matrix[i] = np.zeros(WORD_EMBEDDING_DIM)\n",
    "embedding_layer = Embedding(MAX_WORDS_LIMIT, WORD_EMBEDDING_DIM, weights=[embeddings_matrix], trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f35bc6f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-05T07:07:14.361092Z",
     "iopub.status.busy": "2021-11-05T07:07:14.360612Z",
     "iopub.status.idle": "2021-11-05T07:07:14.362245Z",
     "shell.execute_reply": "2021-11-05T07:07:14.362612Z"
    },
    "papermill": {
     "duration": 0.014386,
     "end_time": "2021-11-05T07:07:14.362720",
     "exception": false,
     "start_time": "2021-11-05T07:07:14.348334",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Approach - 1\n",
    "# # Parameters\n",
    "# sequence_length = X_train.shape[1]\n",
    "# filter_sizes = [3, 4]\n",
    "# num_filters = 128\n",
    "# drop = 0.4\n",
    "\n",
    "# # Obtaining embeddings based on input sequence\n",
    "# inputs = Input(shape=(sequence_length,))\n",
    "# embedding = embedding_layer(inputs)\n",
    "# reshape = Reshape((sequence_length, WORD_EMBEDDING_DIM, 1))(embedding)\n",
    "\n",
    "# # Creating convolutional and maxpool layers\n",
    "# conv_layers, maxpool_layers = [], []\n",
    "# for i in range(2):\n",
    "#     conv_layers.append(Conv2D(num_filters, (filter_sizes[i], WORD_EMBEDDING_DIM), activation='relu', \n",
    "#                               kernel_regularizer=regularizers.l2(0.01))(reshape))\n",
    "#     maxpool_layers.append(MaxPooling2D((sequence_length - filter_sizes[i] + 1, 1), strides=(1, 1))(conv_layers[i]))\n",
    "\n",
    "# # Constructing the complete network and creating model\n",
    "# merged_tensor = concatenate(maxpool_layers, axis=1)\n",
    "# flatten = Flatten()(merged_tensor)\n",
    "# reshape = Reshape((2*num_filters,))(flatten)\n",
    "# dropout = Dropout(drop)(flatten)\n",
    "# conc = Dense(60)(flatten)\n",
    "# output = Dense(units=15, activation='softmax')(conc)\n",
    "# model = Model(inputs, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cleared-drilling",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-05T07:07:14.385746Z",
     "iopub.status.busy": "2021-11-05T07:07:14.385266Z",
     "iopub.status.idle": "2021-11-05T07:07:14.387218Z",
     "shell.execute_reply": "2021-11-05T07:07:14.386829Z"
    },
    "papermill": {
     "duration": 0.014465,
     "end_time": "2021-11-05T07:07:14.387313",
     "exception": false,
     "start_time": "2021-11-05T07:07:14.372848",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Approach - 2\n",
    "# # Parameters\n",
    "# sequence_length = X_train.shape[1]\n",
    "# num_filters = 128\n",
    "# drop = 0.25\n",
    "\n",
    "# # Obtaining embeddings based on input sequence\n",
    "# inputs = Input(shape=(sequence_length,))\n",
    "# embedding = embedding_layer(inputs)\n",
    "# reshape = Reshape((sequence_length, WORD_EMBEDDING_DIM, 1))(embedding)\n",
    "\n",
    "# # Constructing the complete network and creating model\n",
    "# conv = Conv2D(num_filters, (5, WORD_EMBEDDING_DIM), activation='relu', kernel_regularizer=regularizers.l2(0.01))(reshape)\n",
    "# dropout = Dropout(drop)(conv)\n",
    "# pool = MaxPooling2D((sequence_length - 4, 1), strides=(1, 1))(dropout)\n",
    "# flatten = GlobalAveragePooling2D()(pool)\n",
    "# dropout = Dropout(drop)(flatten)\n",
    "# conc = Dense(60)(flatten)\n",
    "# output = Dense(units=15, activation='softmax')(conc)\n",
    "# model = Model(inputs, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb8ca12c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-05T07:07:16.550473Z",
     "iopub.status.busy": "2021-11-05T07:07:14.413833Z",
     "iopub.status.idle": "2021-11-05T07:07:16.813274Z",
     "shell.execute_reply": "2021-11-05T07:07:16.813669Z"
    },
    "papermill": {
     "duration": 2.416029,
     "end_time": "2021-11-05T07:07:16.813802",
     "exception": false,
     "start_time": "2021-11-05T07:07:14.397773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-05 12:37:16.175112: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2021-11-05 12:37:16.523128: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2021-11-05 12:37:16.523189: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1835] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-11-05 12:37:16.524340: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Approach 3\n",
    "# Parameters\n",
    "sequence_length = X_train.shape[1]\n",
    "num_filters = 250\n",
    "drop = 0.25\n",
    "\n",
    "# Obtaining embeddings based on input sequence\n",
    "inputs = Input(shape=(sequence_length,))\n",
    "embedding = embedding_layer(inputs)\n",
    "\n",
    "# Constructing the complete network and creating model\n",
    "conv = Conv1D(num_filters, 5, activation='relu', kernel_regularizer=regularizers.l2(0.01))(embedding)\n",
    "dropout = Dropout(drop)(conv)\n",
    "pool = GlobalMaxPooling1D()(dropout)\n",
    "conc = Dense(100)(pool)\n",
    "dropout2 = Dropout(drop)(conc)\n",
    "output = Dense(units=15, activation='softmax')(dropout2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "hazardous-omaha",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-05T07:07:16.840940Z",
     "iopub.status.busy": "2021-11-05T07:07:16.840487Z",
     "iopub.status.idle": "2021-11-05T16:49:05.625271Z",
     "shell.execute_reply": "2021-11-05T16:49:05.625688Z"
    },
    "papermill": {
     "duration": 34908.800997,
     "end_time": "2021-11-05T16:49:05.625880",
     "exception": false,
     "start_time": "2021-11-05T07:07:16.824883",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################################################################################################\n",
      "\n",
      "With sampling type: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-05 12:37:17.264080: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101/101 - 87s - loss: 2.5126 - accuracy: 0.5333 - val_loss: 1.6889 - val_accuracy: 0.5629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101/101 - 86s - loss: 1.2255 - accuracy: 0.6978 - val_loss: 1.5652 - val_accuracy: 0.5717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101/101 - 86s - loss: 1.0652 - accuracy: 0.7378 - val_loss: 1.4424 - val_accuracy: 0.6039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101/101 - 86s - loss: 0.9705 - accuracy: 0.7677 - val_loss: 1.3893 - val_accuracy: 0.6124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101/101 - 86s - loss: 0.8861 - accuracy: 0.7978 - val_loss: 1.4662 - val_accuracy: 0.5961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101/101 - 86s - loss: 0.8058 - accuracy: 0.8244 - val_loss: 1.4226 - val_accuracy: 0.6083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101/101 - 86s - loss: 0.7378 - accuracy: 0.8490 - val_loss: 1.4037 - val_accuracy: 0.6171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-05 12:47:17.971961: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/CNN_model_1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################################################################################################\n",
      "\n",
      "With sampling type: 3\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101/101 - 86s - loss: 1.0307 - accuracy: 0.7467 - val_loss: 2.4724 - val_accuracy: 0.3976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101/101 - 85s - loss: 0.8858 - accuracy: 0.7828 - val_loss: 2.8630 - val_accuracy: 0.3678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101/101 - 85s - loss: 0.8259 - accuracy: 0.8014 - val_loss: 3.1131 - val_accuracy: 0.3674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101/101 - 85s - loss: 0.7758 - accuracy: 0.8201 - val_loss: 3.8488 - val_accuracy: 0.3340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101/101 - 85s - loss: 0.7350 - accuracy: 0.8330 - val_loss: 3.6737 - val_accuracy: 0.3430\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101/101 - 85s - loss: 0.7048 - accuracy: 0.8450 - val_loss: 4.1230 - val_accuracy: 0.3318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101/101 - 85s - loss: 0.6653 - accuracy: 0.8587 - val_loss: 4.1751 - val_accuracy: 0.3318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/CNN_model_3/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################################################################################################\n",
      "\n",
      "With sampling type: 5\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/tgv2002/miniconda3/envs/py37/lib/python3.7/site-packages/imblearn/under_sampling/_prototype_generation/_cluster_centroids.py:172: ConvergenceWarning: Number of distinct clusters (3728) found smaller than n_clusters (4027). Possibly due to duplicate points in X.\n",
      "  self.estimator_.fit(_safe_indexing(X, target_class_indices))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101/101 - 87s - loss: 1.4023 - accuracy: 0.6755 - val_loss: 1.9200 - val_accuracy: 0.4867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101/101 - 86s - loss: 1.0498 - accuracy: 0.7508 - val_loss: 2.1297 - val_accuracy: 0.4524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101/101 - 86s - loss: 0.9556 - accuracy: 0.7840 - val_loss: 2.1576 - val_accuracy: 0.4721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101/101 - 86s - loss: 0.8669 - accuracy: 0.8175 - val_loss: 2.3790 - val_accuracy: 0.4398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101/101 - 86s - loss: 0.8119 - accuracy: 0.8410 - val_loss: 2.4036 - val_accuracy: 0.4524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101/101 - 86s - loss: 0.7522 - accuracy: 0.8639 - val_loss: 2.7008 - val_accuracy: 0.4295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101/101 - 86s - loss: 0.6875 - accuracy: 0.8885 - val_loss: 2.9034 - val_accuracy: 0.4206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/CNN_model_5/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################################################################################################\n",
      "\n",
      "With sampling type: 6\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455/455 - 323s - loss: 1.1894 - accuracy: 0.6864 - val_loss: 1.2041 - val_accuracy: 0.6718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455/455 - 323s - loss: 1.0661 - accuracy: 0.7058 - val_loss: 1.1672 - val_accuracy: 0.6798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455/455 - 323s - loss: 1.0195 - accuracy: 0.7190 - val_loss: 1.1612 - val_accuracy: 0.6811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455/455 - 324s - loss: 0.9897 - accuracy: 0.7299 - val_loss: 1.1728 - val_accuracy: 0.6788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455/455 - 323s - loss: 0.9664 - accuracy: 0.7396 - val_loss: 1.1884 - val_accuracy: 0.6726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455/455 - 324s - loss: 0.9464 - accuracy: 0.7485 - val_loss: 1.1885 - val_accuracy: 0.6776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455/455 - 323s - loss: 0.9291 - accuracy: 0.7581 - val_loss: 1.2151 - val_accuracy: 0.6724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/CNN_model_6/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################################################################################################\n",
      "\n",
      "Without any oversampling/undersampling\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "498/498 - 352s - loss: 0.9680 - accuracy: 0.7504 - val_loss: 1.1957 - val_accuracy: 0.6777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "498/498 - 351s - loss: 0.9311 - accuracy: 0.7600 - val_loss: 1.2137 - val_accuracy: 0.6712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "498/498 - 351s - loss: 0.9157 - accuracy: 0.7668 - val_loss: 1.2307 - val_accuracy: 0.6711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "498/498 - 351s - loss: 0.8965 - accuracy: 0.7745 - val_loss: 1.2476 - val_accuracy: 0.6649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "498/498 - 351s - loss: 0.8778 - accuracy: 0.7819 - val_loss: 1.2789 - val_accuracy: 0.6591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "498/498 - 351s - loss: 0.8574 - accuracy: 0.7894 - val_loss: 1.2717 - val_accuracy: 0.6658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "498/498 - 352s - loss: 0.8481 - accuracy: 0.7944 - val_loss: 1.2982 - val_accuracy: 0.6574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/CNN_model_-1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################################################################################################\n",
      "\n",
      "With sampling type: 0\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2055/2055 - 1393s - loss: 0.6272 - accuracy: 0.8849 - val_loss: 1.4386 - val_accuracy: 0.6383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2055/2055 - 1394s - loss: 0.5800 - accuracy: 0.8977 - val_loss: 1.4784 - val_accuracy: 0.6347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2055/2055 - 1395s - loss: 0.5499 - accuracy: 0.9052 - val_loss: 1.5218 - val_accuracy: 0.6286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2055/2055 - 1395s - loss: 0.5252 - accuracy: 0.9115 - val_loss: 1.5337 - val_accuracy: 0.6237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2055/2055 - 1396s - loss: 0.5083 - accuracy: 0.9156 - val_loss: 1.5876 - val_accuracy: 0.6205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2055/2055 - 1396s - loss: 0.4914 - accuracy: 0.9195 - val_loss: 1.5837 - val_accuracy: 0.6295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2055/2055 - 1396s - loss: 0.4788 - accuracy: 0.9229 - val_loss: 1.5808 - val_accuracy: 0.6258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/CNN_model_0/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################################################################################################\n",
      "\n",
      "With sampling type: 2\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2055/2055 - 1393s - loss: 2.5923 - accuracy: 0.2463 - val_loss: 1.5917 - val_accuracy: 0.6188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2055/2055 - 1394s - loss: 2.4424 - accuracy: 0.2660 - val_loss: 1.5990 - val_accuracy: 0.6199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2055/2055 - 1395s - loss: 2.4240 - accuracy: 0.2721 - val_loss: 1.5488 - val_accuracy: 0.6217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2055/2055 - 1395s - loss: 2.4083 - accuracy: 0.2768 - val_loss: 1.5439 - val_accuracy: 0.6211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2055/2055 - 1396s - loss: 2.3937 - accuracy: 0.2809 - val_loss: 1.5211 - val_accuracy: 0.6143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2055/2055 - 1396s - loss: 2.3831 - accuracy: 0.2848 - val_loss: 1.5411 - val_accuracy: 0.6123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2055/2055 - 1396s - loss: 2.3733 - accuracy: 0.2882 - val_loss: 1.5623 - val_accuracy: 0.6096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/CNN_model_2/assets\n"
     ]
    }
   ],
   "source": [
    "# Fitting Model to the data\n",
    "X_tr, y_tr = X_train, y_train\n",
    "for _type in [1, 3, 5, 6, -1, 0, 2]:\n",
    "    model = Model(inputs, output)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=1e-3), metrics=[\"accuracy\"])\n",
    "    print('#'*110)\n",
    "    print()\n",
    "    if _type == -1:\n",
    "        print('Without any oversampling/undersampling')\n",
    "    else:\n",
    "        print(f'With sampling type: {_type}')\n",
    "    print()\n",
    "    print()\n",
    "    X_train, y_train = balance_data(X_tr, y_tr, _type)\n",
    "    hist_adam = model.fit(X_train, y_train, batch_size=600, epochs=7, verbose=2, \n",
    "                          validation_data=(X_valid, y_valid))\n",
    "    # Saving model\n",
    "    model.save(f'../models/CNN_model_{_type}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc138058",
   "metadata": {
    "papermill": {
     "duration": 0.03622,
     "end_time": "2021-11-05T16:49:05.698810",
     "exception": false,
     "start_time": "2021-11-05T16:49:05.662590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 35032.239089,
   "end_time": "2021-11-05T16:49:09.390560",
   "environment_variables": {},
   "exception": null,
   "input_path": "Training.ipynb",
   "output_path": "Training_output.ipynb",
   "parameters": {},
   "start_time": "2021-11-05T07:05:17.151471",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}